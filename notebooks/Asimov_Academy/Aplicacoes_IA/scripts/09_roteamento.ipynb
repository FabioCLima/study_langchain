{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roteamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is **blue** (during the day) due to the scattering of sunlight by the atmosphere. This phenomenon is called **Rayleigh scattering**. At sunrise and sunset, the sky can appear **red, orange, or pink** because the sunlight passes through more of the atmosphere, scattering shorter blue wavelengths and allowing longer red wavelengths to dominate.\n",
      "\n",
      "At night, the sky appears **dark or black**, dotted with stars, because the sun is no longer illuminating the atmosphere from your location.\n",
      "\n",
      "So, the sky **can be blue, red, orange, pink, gray, or black** depending on the time of day, weather, and atmospheric conditions.\n"
     ]
    }
   ],
   "source": [
    "# * Carrega as variáveis de ambiente\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# * Verifica se a API key está configurada\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY não encontrada no arquivo .env\")\n",
    "\n",
    "# * Configura o modelo com parâmetros específicos\n",
    "model: ChatOpenAI = ChatOpenAI(\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature=0.0,  # Controla a criatividade das respostas\n",
    ")  # type: ignore\n",
    "\n",
    "response = model.invoke(\"The Sky is ?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"Você é um professor de matemática de ensino fundamental\n",
    "capaz de dar respostas muito detalhadas e didáticas. Responda a seguinte pergunta de um aluno:\n",
    "Pergunta: {pergunta}\"\"\")\n",
    "chain_matematica = prompt | model\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Você é um professor de física de ensino fundamental\n",
    "capaz de dar respostas muito detalhadas e didáticas. Responda a seguinte pergunta de um aluno:\n",
    "Pergunta: {pergunta}\"\"\")\n",
    "chain_fisica = prompt | model\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Você é um professor de história de ensino fundamental\n",
    "capaz de dar respostas muito detalhadas e didáticas. Responda a seguinte pergunta de um aluno:\n",
    "Pergunta: {pergunta}\"\"\")\n",
    "chain_historia = prompt | model\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"{pergunta}\"\"\")\n",
    "chain_generica = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorizador(area_conhecimento='história')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Você deve categorizar a seguinte pergunta: {pergunta}\"\n",
    ")\n",
    "\n",
    "\n",
    "class Categorizador(BaseModel):\n",
    "    \"\"\"Categoriza as perguntas de alunos do ensino fundamental\"\"\"\n",
    "\n",
    "    area_conhecimento: str = Field(\n",
    "        description='A área de conhecimento da pergunta feita pelo aluno. \\\n",
    "    Deve ser \"física\", \"matemática\" ou \"história\". Caso não se encaixe em nenhuma delas, retorne \"outra\"'\n",
    "    )\n",
    "\n",
    "\n",
    "model_estruturado = prompt | model.with_structured_output(Categorizador)\n",
    "model_estruturado.invoke({\"pergunta\": \"Quando foi a inependencia dos estados unidos?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando estrutura de roteamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pergunta': 'Quando foi a independencia dos estados unidos?',\n",
       " 'categoria': Categorizador(area_conhecimento='história')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough().assign(categoria=model_estruturado)\n",
    "chain.invoke({\"pergunta\": \"Quando foi a independencia dos estados unidos?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(input):\n",
    "    if input[\"categoria\"].area_conhecimento == \"matemática\":\n",
    "        return chain_matematica\n",
    "    if input[\"categoria\"].area_conhecimento == \"física\":\n",
    "        return chain_fisica\n",
    "    if input[\"categoria\"].area_conhecimento == \"história\":\n",
    "        return chain_historia\n",
    "    return chain_generica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough().assign(categoria=model_estruturado) | route\n",
    "chain.invoke({\"pergunta\": \"Quando foi a inependencia dos estados unidos?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"pergunta\": \"Quanto é 1 + 21?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
