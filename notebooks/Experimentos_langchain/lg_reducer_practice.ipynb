{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a190c3e2",
   "metadata": {},
   "source": [
    "### Praticando Reduces no LangGraph\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bc027",
   "metadata": {},
   "source": [
    "Exercício Prático: \n",
    "--**Planejador de Viagens Parelelo**\n",
    "\n",
    "    Vamos criar um grafo simples que para, um dada cidade, busca sugestões de restaurantes e de atrações turísticas em parelelo e as combina em um única lista de sugestões.\n",
    "\n",
    "    1. Um NODE para buscar os restaurantes\n",
    "    2. Um NODE para buscar atrações turísticas\n",
    "    3. Uso do REDUCER para combinar em um única lista de sugestões\n",
    "    4. Criação do STATE com pydantic, garantindo robustez e validação da estrutura de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7908e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * 1. Importação das bibliotecas\n",
    "import operator\n",
    "import os\n",
    "from typing import Annotated\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import Image, display  # pyright: ignore[reportUnknownVariableType]\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from loguru import logger\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# * 2. Configuração do ambiente\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe41e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 11:41:42.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mAmbiente e bibliotecas carregados com sucesso.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 3. Configuração do LangSmith (Opcional, mas recomendado)\n",
    "# Certifique-se de que as seguintes variáveis estão no seu .env:\n",
    "# LANGCHAIN_TRACING_V2=\"true\"\n",
    "# LANGCHAIN_API_KEY=\"sua_api_key\"\n",
    "# LANGCHAIN_PROJECT=\"seu_nome_de_projeto\" (ex: \"LangGraph - Travel Planner\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = (\n",
    "    \"Exercício - Travel Planner\"  # Você pode nomear como quiser\n",
    ")\n",
    "\n",
    "# 4. Configuração do Logger\n",
    "logger.add(\"output.log\", rotation=\"10 MB\", level=\"INFO\")\n",
    "logger.info(\"Ambiente e bibliotecas carregados com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TravelState(BaseModel):\n",
    "    \"\"\"Representa o estado do grafo do planejador de viagens.\n",
    "\n",
    "    Esta classe define a estrutura de dados que será passada entre os nós\n",
    "    do grafo. Ela armazena a cidade de entrada e acumula as sugestões\n",
    "    coletadas.\n",
    "\n",
    "    Attributes:\n",
    "        city (str): A cidade para a qual as sugestões serão buscadas.\n",
    "        suggestions (list[str]): Uma lista que acumula sugestões de restaurantes\n",
    "            e atrações. Utiliza um redutor (`operator.add`) para combinar\n",
    "            resultados de nós que executam em paralelo.\n",
    "    \"\"\"\n",
    "\n",
    "    city: str = Field(\n",
    "        ..., description=\"A cidade para a qual as sugestões serão buscadas.\"\n",
    "    )\n",
    "\n",
    "    suggestions: Annotated[list[str], operator.add] = Field(\n",
    "        default_factory=list, description=\"Lista combinada de restaurantes e atrações.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35693869",
   "metadata": {},
   "source": [
    "Definição do NODE: `get_restaurants`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1eb62",
   "metadata": {},
   "source": [
    "1. Criação do modelo de dados usados pela classe RestaurantSuggestions - que será usada no primeiro NODE, pela LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Este modelo define a estrutura de saída da LLM que será usada para buscar restaurantes\n",
    "class RestaurantSuggestions(BaseModel):\n",
    "    \"\"\"Modelo para sugestões de restaurantes.\n",
    "\n",
    "    Este modelo define a estrutura de saída que será produzida pela LLM.\n",
    "    Ele garante que sempre haverá uma lista fixa de restaurantes sugeridos,\n",
    "    com no mínimo e no máximo três itens.\n",
    "\n",
    "    Attributes:\n",
    "        restaurants (list[str]): Lista de restaurantes sugeridos pela LLM.\n",
    "            Deve conter exatamente 3 itens (min_items=3, max_items=3).\n",
    "    \"\"\"\n",
    "\n",
    "    restaurants: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"Lista de restaurantes sugeridos pela LLM\",\n",
    "        min_items=3,\n",
    "        max_items=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88dc4d",
   "metadata": {},
   "source": [
    "2. Criação da chain que será usada para gerar a sugestão de restaurantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b693fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# * 1. Instanciar o LLM com suporte a structured output\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# * 2. Habilitar saída estruturada diretamente no LLM\n",
    "llm_with_parser = llm.with_structured_output(RestaurantSuggestions)\n",
    "\n",
    "# * 3. Criar o Prompt Template\n",
    "prompt_restaurants = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Você é um assistente especialista em viagens e gastronomia. \"\n",
    "            \"Responda com exatamente 3 restaurantes de qualidade.\",\n",
    "        ),\n",
    "        (\"user\", \"Sugira restaurantes na cidade de {city}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# * 4. Montar a chain final\n",
    "chain_restaurants = prompt_restaurants | llm_with_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9059d5",
   "metadata": {},
   "source": [
    "Criando o NODE que busca os restaurantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb176070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurants_node(state: TravelState) -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Executa uma chain para obter 3 sugestões de restaurantes para a cidade\n",
    "    especificada no estado e as retorna para serem adicionadas à lista de sugestões.\n",
    "\n",
    "    Args:\n",
    "        state (TravelState): O estado atual do grafo, que contém a cidade.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, list[str]]: Um dicionário cuja chave corresponde ao campo do\n",
    "                               estado que deve ser atualizado. O valor é o dado\n",
    "                               a ser enviado para o reducer.\n",
    "    \"\"\"\n",
    "    # * 1. Extrai a informação necessária do estado de entrada.\n",
    "    city = state.city\n",
    "    logger.info(f\"Iniciando busca de restaurantes para a cidade: {city}\")\n",
    "\n",
    "    # * 2. Invoca a chain que você criou.\n",
    "    #    A entrada da chain é um dicionário cuja chave 'city' corresponde\n",
    "    #    à variável {city} no seu prompt.\n",
    "    suggestions_object = chain_restaurants.invoke({\"city\": city})\n",
    "\n",
    "    # * 3. Extrai a lista de nomes do objeto Pydantic que a chain retornou.\n",
    "    #    'suggestions_object' é uma instância da sua classe 'RestaurantSuggestions'.\n",
    "    restaurant_names = suggestions_object.restaurants\n",
    "    logger.info(f\"Restaurantes encontrados: {restaurant_names}\")\n",
    "\n",
    "    # * 4. Retorna o resultado no formato que o LangGraph espera.\n",
    "    #    - DEVE ser um dicionário.\n",
    "    #    - A chave \"suggestions\" DEVE ser o nome exato do atributo no TravelState\n",
    "    #      que você quer atualizar.\n",
    "    #    - O valor (restaurant_names) será passado para o reducer (operator.add).\n",
    "    return {\"suggestions\": restaurant_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbeb36",
   "metadata": {},
   "source": [
    "Gerar o modelo de dados para lista de atrações, prompt, chain e por fim o node get_attractions_node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloco de Código para o Nó de Atrações ---\n",
    "\n",
    "# 1. Definição do Schema de Saída com Pydantic\n",
    "class AttractionSuggestions(BaseModel):\n",
    "    \"\"\"Modelo para sugestões de atrações turísticas.\"\"\"\n",
    "\n",
    "    attractions: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"Lista de atrações turísticas sugeridas pela LLM\",\n",
    "        min_items=3,\n",
    "        max_items=3,\n",
    "    )\n",
    "\n",
    "\n",
    "# 2. Habilitar saída estruturada diretamente no LLM\n",
    "# Presumindo que o 'llm' (ChatOpenAI) já foi instanciado na célula anterior\n",
    "llm_with_parser_attractions = llm.with_structured_output(AttractionSuggestions)\n",
    "\n",
    "# 3. Criar o Prompt Template específico para atrações\n",
    "prompt_attractions = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Você é um assistente especialista em viagens e cultura. \"\n",
    "            \"Responda com exatamente 3 atrações turísticas imperdíveis.\",\n",
    "        ),\n",
    "        (\"user\", \"Sugira atrações turísticas na cidade de {city}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Montar a chain final para atrações\n",
    "chain_attractions = prompt_attractions | llm_with_parser_attractions\n",
    "\n",
    "\n",
    "# 5. Função final do Nó para o LangGraph\n",
    "def get_attractions_node(state: TravelState) -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Executa uma chain para obter 3 sugestões de atrações para a cidade\n",
    "    e as retorna para serem adicionadas à lista de sugestões.\n",
    "    \"\"\"\n",
    "    city = state.city\n",
    "    logger.info(f\"Iniciando busca de atrações para a cidade: {city}\")\n",
    "\n",
    "    # Invoca a chain de atrações\n",
    "    suggestions_object = chain_attractions.invoke({\"city\": city})\n",
    "\n",
    "    # Extrai a lista do objeto Pydantic\n",
    "    attraction_names = suggestions_object.attractions\n",
    "    logger.info(f\"Atrações encontradas: {attraction_names}\")\n",
    "\n",
    "    # Retorna o dicionário com a MESMA chave 'suggestions' para o reducer\n",
    "    return {\"suggestions\": attraction_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7781e",
   "metadata": {},
   "source": [
    "Gerar o grafo e usar o reducer para juntar as saídas em paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e5edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 11:41:43.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mStateGraph instanciado com o estado TravelState.\u001b[0m\n",
      "\u001b[32m2025-09-19 11:41:43.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mNós 'restaurants' e 'attractions' adicionados ao workflow.\u001b[0m\n",
      "\u001b[32m2025-09-19 11:41:43.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mArestas definidas para execução paralela do START para ambos os nós, e de ambos para o END.\u001b[0m\n",
      "\u001b[32m2025-09-19 11:41:43.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mGrafo compilado com sucesso e atribuído à variável 'graph'.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafo compilado com sucesso e pronto para ser executado!\n"
     ]
    }
   ],
   "source": [
    "# --- Bloco de Montagem do Grafo ---\n",
    "\n",
    "# 1. Instanciar o Grafo\n",
    "# Criamos o \"construtor\" do grafo, associando-o ao nosso modelo de estado TravelState.\n",
    "# Vamos usar a variável 'graph' para o construtor, como é comum.\n",
    "graph = StateGraph(TravelState)\n",
    "logger.info(\"StateGraph instanciado com o estado TravelState.\")\n",
    "\n",
    "# 2. Adicionar os Nós\n",
    "# Damos um nome (string) para cada nó e o associamos à sua respectiva função.\n",
    "graph.add_node(\"restaurants\", get_restaurants_node)\n",
    "graph.add_node(\"attractions\", get_attractions_node)\n",
    "logger.info(\"Nós 'restaurants' e 'attractions' adicionados ao workflow.\")\n",
    "\n",
    "# 3. Definir as Arestas (Edges) para Execução Paralela\n",
    "# A partir do início (START), o fluxo é direcionado para AMBOS os nós.\n",
    "# Isso informa ao LangGraph para executá-los em paralelo.\n",
    "graph.add_edge(START, \"restaurants\")\n",
    "graph.add_edge(START, \"attractions\")\n",
    "\n",
    "# Após cada nó terminar sua execução, o grafo pode chegar ao fim (END).\n",
    "graph.add_edge(\"restaurants\", END)\n",
    "graph.add_edge(\"attractions\", END)\n",
    "logger.info(\n",
    "    \"Arestas definidas para execução paralela do START para ambos os nós, e de ambos para o END.\"\n",
    ")\n",
    "\n",
    "# 4. Compilar o Grafo\n",
    "# O método .compile() transforma nossa definição em um objeto executável.\n",
    "# Usando a variável final 'graph' como você sugeriu.\n",
    "graph = graph.compile()\n",
    "\n",
    "print(\"Grafo compilado com sucesso e pronto para ser executado!\")\n",
    "logger.info(\"Grafo compilado com sucesso e atribuído à variável 'graph'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e2460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 11:41:43.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mIniciando a invocação do grafo para a cidade: Alto Paraíso\u001b[0m\n",
      "\u001b[32m2025-09-19 11:41:43.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_attractions_node\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mIniciando busca de atrações para a cidade: Alto Paraíso\u001b[0m\n",
      "\u001b[32m2025-09-19 11:41:43.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_restaurants_node\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mIniciando busca de restaurantes para a cidade: Alto Paraíso\u001b[0m\n",
      "\u001b[32m2025-09-19 11:41:45.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_restaurants_node\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mRestaurantes encontrados: ['Café do Cerrado', \"Restaurante Roda D'Água\", 'Vila do Cerrado']\u001b[0m\n",
      "\u001b[32m2025-09-19 11:41:45.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_attractions_node\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mAtrações encontradas: ['Cataratas dos Couros', 'Parque Nacional da Chapada dos Veadeiros', 'Véu de Noiva e o Morro da Baleia']\u001b[0m\n",
      "\u001b[32m2025-09-19 11:41:45.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mGrafo executado com sucesso.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESULTADO FINAL COMBINADO ---\n",
      "Sugestões para Alto Paraíso:\n",
      "- Cataratas dos Couros\n",
      "- Parque Nacional da Chapada dos Veadeiros\n",
      "- Véu de Noiva e o Morro da Baleia\n",
      "- Café do Cerrado\n",
      "- Restaurante Roda D'Água\n",
      "- Vila do Cerrado\n",
      "\n",
      "--- ESTRUTURA DO GRAFO (PNG) ---\n",
      "Não foi possível gerar a imagem do grafo. Verifique as dependências (ex: pygraphviz). Erro: Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n"
     ]
    }
   ],
   "source": [
    "# --- Bloco de Execução e Visualização ---\n",
    "\n",
    "# 1. Definir o input para o grafo\n",
    "# A chave 'city' deve corresponder ao atributo no nosso TravelState.\n",
    "cidade_para_pesquisar = \"Alto Paraíso\"\n",
    "input_data = {\"city\": cidade_para_pesquisar}\n",
    "logger.info(f\"Iniciando a invocação do grafo para a cidade: {cidade_para_pesquisar}\")\n",
    "\n",
    "# 2. Invocar o grafo com os dados de entrada\n",
    "# O LangSmith irá capturar este traço para podermos depurar e observar.\n",
    "final_result = graph.invoke(input_data)\n",
    "logger.info(\"Grafo executado com sucesso.\")\n",
    "\n",
    "# 3. Imprimir o resultado final e combinado\n",
    "print(\"--- RESULTADO FINAL COMBINADO ---\")\n",
    "print(f\"Sugestões para {final_result['city']}:\")\n",
    "# O 'final_result' é o estado final, e nossa lista combinada está na chave 'suggestions'.\n",
    "for suggestion in final_result[\"suggestions\"]:\n",
    "    print(f\"- {suggestion}\")\n",
    "\n",
    "# 4. Gerar e exibir a imagem do grafo\n",
    "print(\"\\n--- ESTRUTURA DO GRAFO (PNG) ---\")\n",
    "try:\n",
    "    # O método .get_graph() nos dá acesso à estrutura,\n",
    "    # e .draw_mermaid_png() a renderiza como uma imagem.\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"Não foi possível gerar a imagem do grafo. Verifique as dependências (ex: pygraphviz). Erro: {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81695a1",
   "metadata": {},
   "source": [
    "![Diagrama do Grafo com Reducer](/home/fabiolima/Workdir/langchain/study_langchain/notebooks/reducer_langgraph_diagram.png \"Grafo com Reducer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3260f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conclusão e Resumo do Exercício\n",
    "\n",
    "Este notebook demonstrou a construção de um grafo computacional paralelo utilizando LangGraph para resolver um problema prático: a criação de um planejador de viagens. O objetivo principal era buscar, de forma simultânea, sugestões de restaurantes e atrações turísticas para uma cidade e, em seguida, combinar os resultados em uma única lista coesa.\n",
    "\n",
    "A seguir, detalhamos o passo a passo da implementação.\n",
    "\n",
    "#### Passo 1: Preparação do Ambiente\n",
    "A base de qualquer projeto robusto é um ambiente bem configurado. Iniciamos importando todas as bibliotecas necessárias, incluindo `langgraph`, `pydantic`, `langchain_openai`, `loguru` para logs detalhados e `dotenv` para o gerenciamento de chaves de API. Também configuramos o `LangSmith` para garantir a observabilidade e o rastreamento da execução do nosso grafo, o que é fundamental para a depuração.\n",
    "\n",
    "#### Passo 2: Design Centrado no Estado (State-First)\n",
    "A \"memória\" ou o \"estado\" do nosso grafo foi definida usando a classe `TravelState`, que herda de `pydantic.BaseModel` para garantir a validação e a clareza dos dados. O componente mais crítico desta classe foi o atributo `suggestions`. Ao tipá-lo como `Annotated[list[str], operator.add]`, instruímos o LangGraph a usar a função `operator.add` como um **reducer**. Isso significa que, quando múltiplos nós tentarem escrever nesta lista ao mesmo tempo, seus resultados serão concatenados em vez de sobrescritos ou gerarem um erro.\n",
    "\n",
    "#### Passo 3: Construção dos Nós Inteligentes\n",
    "Cada tarefa principal foi encapsulada em um \"nó\" do grafo. Construímos dois nós: `get_restaurants_node` e `get_attractions_node`. Para garantir que a saída de cada nó fosse confiável e bem estruturada, seguimos um padrão moderno e robusto:\n",
    "1.  **Definição de um Schema de Saída:** Para cada nó, criamos uma classe Pydantic (`RestaurantSuggestions` e `AttractionSuggestions`) que define a estrutura exata da resposta que esperamos do LLM (uma lista com 3 strings).\n",
    "2.  **Saída Estruturada:** Utilizamos o método `.with_structured_output()` no nosso LLM (`ChatOpenAI`). Esta é a prática recomendada para forçar o modelo a retornar um JSON que adere perfeitamente ao nosso schema Pydantic.\n",
    "3.  **Criação de uma Chain:** Combinamos o prompt, o LLM com parser e a lógica de chamada em uma `chain` da LangChain Expression Language (LCEL).\n",
    "4.  **Função do Nó:** A função do nó atuou como uma \"ponte\", recebendo o estado do grafo, extraindo a cidade, invocando a `chain` e retornando um dicionário com a chave `\"suggestions\"`, garantindo que o resultado fosse direcionado para o reducer.\n",
    "\n",
    "#### Passo 4: Montagem e Execução do Grafo Paralelo\n",
    "Com os nós prontos, montamos o grafo:\n",
    "* Adicionamos os dois nós (`restaurants` e `attractions`) ao nosso `StateGraph`.\n",
    "* A execução paralela foi definida ao criarmos duas **arestas (edges)** a partir do ponto de entrada `START`, uma para cada nó (`START -> restaurants` e `START -> attractions`).\n",
    "* Conectamos ambos os nós ao ponto de finalização `END`.\n",
    "* Finalmente, compilamos o grafo e o invocamos com uma cidade. O resultado, impresso na tela, foi uma lista única contendo 6 sugestões (3 restaurantes e 3 atrações), validando que a execução paralela e a combinação com o reducer foram um sucesso.\n",
    "\n",
    "#### Principais Aprendizados\n",
    "* **Paralelismo em LangGraph:** Como estruturar um fluxo de trabalho onde múltiplas tarefas ocorrem simultaneamente.\n",
    "* **Reducers para Gerenciamento de Estado:** O uso de `Annotated` para resolver conflitos de escrita e agregar dados de forma inteligente.\n",
    "* **Robustez com Pydantic:** A utilização de Pydantic tanto para definir o estado do grafo quanto para garantir a saída estruturada e validada de LLMs.\n",
    "* **Observabilidade:** A importância de ferramentas como `loguru` e `LangSmith` para entender e depurar o comportamento do grafo.\n",
    "* **Tipos de dados no Reducers:** Todos os nós que escrevem na mesma chave de estado com um reducer devem retornar o mesmo tipo de dado que a função redutora espera para poder operar corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273fcf2",
   "metadata": {},
   "source": [
    "# TODO \n",
    "1. Acrescentar mais 2 nós, mudar o graph.\n",
    "2. Adicionar e modificar com o código a seguir `down below code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242dae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloco de Código para os Novos Nós: Cultural e Contemplativo ---\n",
    "\n",
    "# 1a. Schema Pydantic para Passeios Culturais\n",
    "class CulturalSuggestions(BaseModel):\n",
    "    \"\"\"Modelo para sugestões de passeios culturais.\"\"\"\n",
    "\n",
    "    cultural_tours: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"Lista de 2 sugestões de passeios culturais.\",\n",
    "        min_length=2,\n",
    "        max_length=2,\n",
    "    )\n",
    "\n",
    "\n",
    "# 1b. Schema Pydantic para Passeios Contemplativos\n",
    "class ContemplativeSuggestions(BaseModel):\n",
    "    \"\"\"Modelo para sugestões de passeios contemplativos.\"\"\"\n",
    "\n",
    "    contemplative_tours: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"Lista de 2 sugestões de passeios contemplativos.\",\n",
    "        min_length=2,\n",
    "        max_length=2,\n",
    "    )\n",
    "\n",
    "\n",
    "# Presumindo que 'llm' já foi instanciado\n",
    "# 2a. Chain para Passeios Culturais\n",
    "llm_with_parser_cultural = llm.with_structured_output(CulturalSuggestions)\n",
    "prompt_cultural = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Você é um guia turístico especializado na cultura e história local. Sugira 2 atividades culturais autênticas.\",\n",
    "        ),\n",
    "        (\"user\", \"Quais são os melhores passeios culturais na cidade de {city}?\"),\n",
    "    ]\n",
    ")\n",
    "chain_cultural = prompt_cultural | llm_with_parser_cultural\n",
    "\n",
    "# 2b. Chain para Passeios Contemplativos\n",
    "llm_with_parser_contemplative = llm.with_structured_output(ContemplativeSuggestions)\n",
    "prompt_contemplative = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Você é um guia de ecoturismo e bem-estar. Sugira 2 passeios focados em contemplação da natureza, como ver o pôr do sol, nascer da lua ou observação de pássaros.\",\n",
    "        ),\n",
    "        (\"user\", \"Quais são os melhores passeios contemplativos na cidade de {city}?\"),\n",
    "    ]\n",
    ")\n",
    "chain_contemplative = prompt_contemplative | llm_with_parser_contemplative\n",
    "\n",
    "\n",
    "# 3a. Função do Nó Cultural\n",
    "def get_cultural_node(state: TravelState) -> dict[str, list[str]]:\n",
    "    city = state.city\n",
    "    logger.info(f\"Iniciando busca de passeios CULTURAIS para: {city}\")\n",
    "    suggestions = chain_cultural.invoke({\"city\": city})\n",
    "    logger.info(f\"Passeios culturais encontrados: {suggestions.cultural_tours}\")\n",
    "    return {\"suggestions\": suggestions.cultural_tours}\n",
    "\n",
    "\n",
    "# 3b. Função do Nó Contemplativo\n",
    "def get_contemplative_node(state: TravelState) -> dict[str, list[str]]:\n",
    "    city = state.city\n",
    "    logger.info(f\"Iniciando busca de passeios CONTEMPLATIVOS para: {city}\")\n",
    "    suggestions = chain_contemplative.invoke({\"city\": city})\n",
    "    logger.info(\n",
    "        f\"Passeios contemplativos encontrados: {suggestions.contemplative_tours}\"\n",
    "    )\n",
    "    return {\"suggestions\": suggestions.contemplative_tours}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddee4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloco de Montagem do Grafo ATUALIZADO (4 nós paralelos) ---\n",
    "\n",
    "# 1. Instanciar o Grafo\n",
    "graph_v2 = StateGraph(TravelState)\n",
    "\n",
    "# 2. Adicionar TODOS os quatro nós\n",
    "graph_v2.add_node(\"restaurants\", get_restaurants_node)\n",
    "graph_v2.add_node(\"attractions\", get_attractions_node)\n",
    "graph_v2.add_node(\"cultural\", get_cultural_node)\n",
    "graph_v2.add_node(\"contemplative\", get_contemplative_node)\n",
    "\n",
    "# 3. Definir as Arestas para Execução Paralela\n",
    "# O START agora dispara QUATRO nós ao mesmo tempo!\n",
    "graph_v2.add_edge(START, \"restaurants\")\n",
    "graph_v2.add_edge(START, \"attractions\")\n",
    "graph_v2.add_edge(START, \"cultural\")\n",
    "graph_v2.add_edge(START, \"contemplative\")\n",
    "\n",
    "# 4. Conectar todos os nós ao FIM\n",
    "graph_v2.add_edge(\"restaurants\", END)\n",
    "graph_v2.add_edge(\"attractions\", END)\n",
    "graph_v2.add_edge(\"cultural\", END)\n",
    "graph_v2.add_edge(\"contemplative\", END)\n",
    "\n",
    "# 5. Compilar o novo grafo\n",
    "compiled_graph_v2 = graph_v2.compile()\n",
    "\n",
    "print(\"Grafo V2 com 4 nós paralelos compilado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO \n",
    "\n",
    "6. Conceitos-chave destacados\n",
    "Fluxos de trabalho sequenciais são simples porque cada nó modifica o estado um após o outro.\n",
    "Fluxos de trabalho paralelos exigem reducers para evitar conflitos de atualização.\n",
    "Reducers definem como mesclar atualizações simultâneas:\n",
    "- Somar números → Soma\n",
    "- Somar listas → Concatenação\n",
    "- Somar mensagens → Agregação de mensagens\n",
    "MessageState simplifica o uso de mensagens do LangChain em fluxos de trabalho sem a necessidade de esquemas personalizados.\n",
    "\n",
    "7. Conclusão\n",
    "Reducers são essenciais para uma execução paralela segura e correta no LangGraph.\n",
    "Eles permitem que múltiplos nós contribuam para o mesmo campo sem perda de dados ou colisões.\n",
    "Projetar corretamente o estado e os reducers possibilita fluxos de trabalho em grafo escaláveis e modulares.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
