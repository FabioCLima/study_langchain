{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Digite sua chave de API do OpenAI: \"\n",
    "    )\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Exerc√≠cio 1 ‚Äì Resumo com `LLMChain`\n",
    "**Objetivo:** Usar um `PromptTemplate` com uma vari√°vel para gerar um resumo curto de um texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fotoss√≠ntese √© a convers√£o de luz solar em energia qu√≠mica pelas plantas.\n"
     ]
    }
   ],
   "source": [
    "# üîß Sua tentativa aqui:\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "template = \"Resuma o seguinte texto em uma frase:\\n{texto}\"\n",
    "prompt = PromptTemplate(input_variables=[\"texto\"], template=template)\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "chain = prompt | model | output_parser\n",
    "texto = \"A fotoss√≠ntese √© um processo biol√≥gico no qual as plantas convertem luz solar em energia qu√≠mica.\"\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"texto\": \"A fotoss√≠ntese √© um processo biol√≥gico no qual as plantas convertem luz solar em energia qu√≠mica.\"\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Exerc√≠cio 2 ‚Äì T√≠tulo + Resumo (SimpleSequentialChain)\n",
    "**Objetivo:** Criar dois passos encadeados: gerar t√≠tulo e depois resumo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_prompt = PromptTemplate(\n",
    "    input_variables=[\"texto\"],\n",
    "    template=\"Gere um t√≠tulo criativo para o seguinte texto:\\n{texto}\",\n",
    ")\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"texto\"],\n",
    "    template=\"Resuma o seguinte texto em duas frases:\\n{texto}\",\n",
    ")\n",
    "title_chain = LLMChain(llm=llm, prompt=title_prompt)\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "overall_chain = SimpleSequentialChain(chains=[title_chain, summary_chain], verbose=True)\n",
    "entrada = \"A energia solar √© uma fonte renov√°vel e abundante, ideal para combater as mudan√ßas clim√°ticas.\"\n",
    "resultado = overall_chain.run(entrada)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Exerc√≠cio 3 ‚Äì Explica√ß√£o T√©cnica + Vers√£o Infantil\n",
    "**Objetivo:** Criar um encadeamento de dois passos:\n",
    "1. Explica√ß√£o t√©cnica de um conceito\n",
    "2. Reescrever de forma simples para uma crian√ßa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explica_prompt = PromptTemplate(\n",
    "    input_variables=[\"conceito\"],\n",
    "    template=\"Explique de forma t√©cnica o conceito de: {conceito}\",\n",
    ")\n",
    "infantil_prompt = PromptTemplate(\n",
    "    input_variables=[\"conceito\"],\n",
    "    template=\"Explique de forma simples para uma crian√ßa de 10 anos: {conceito}\",\n",
    ")\n",
    "explica_chain = LLMChain(llm=llm, prompt=explica_prompt)\n",
    "infantil_chain = LLMChain(llm=llm, prompt=infantil_prompt)\n",
    "chain = SimpleSequentialChain(chains=[explica_chain, infantil_chain], verbose=True)\n",
    "chain.run(\"fotoss√≠ntese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Exerc√≠cio 4 ‚Äì Componente externo (simulado)\n",
    "**Objetivo:** Simular a busca de informa√ß√µes externas e resumir a resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulando resposta de uma API\n",
    "informacao = \"Alan Turing foi um matem√°tico brit√¢nico considerado um dos pais da ci√™ncia da computa√ß√£o.\"\n",
    "prompt_busca = PromptTemplate.from_template(\n",
    "    \"Resuma a seguinte informa√ß√£o em 1 frase:\\n{info}\"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_busca)\n",
    "print(chain.run(info=informacao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Exerc√≠cio 5 ‚Äì Plano de Estudo Inteligente (Chain + l√≥gica Python)\n",
    "**Objetivo:** Dividir um tema em subtemas e gerar um plano de estudos proporcional √†s horas dispon√≠veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tema = \"Machine Learning\"\n",
    "horas = 10\n",
    "subtemas_prompt = PromptTemplate.from_template(\n",
    "    \"Divida o tema '{tema}' em 3 subtemas de estudo.\"\n",
    ")\n",
    "subtemas_chain = LLMChain(llm=llm, prompt=subtemas_prompt)\n",
    "subtemas = subtemas_chain.run(tema=tema)\n",
    "# Dividir horas entre os subtemas\n",
    "lista = subtemas.split(\"\\n\") if \"\\n\" in subtemas else subtemas.split(\",\")\n",
    "horas_por_subtema = horas // len(lista)\n",
    "print(\"Plano de estudos:\\n\")\n",
    "for s in lista:\n",
    "    print(f\"{s.strip()}: {horas_por_subtema}h por semana\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
