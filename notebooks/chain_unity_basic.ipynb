{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4c01b8",
   "metadata": {},
   "source": [
    "## ExercÃ­cios bÃ¡sicos sobre LCEL - LangChain\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd46a2d",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## CONCEITOS FUNDAMENTAIS DO LANGCHAIN\n",
    "## =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "ğŸ¯ CORE COMPONENTS DE UMA APLICAÃ‡ÃƒO LANGCHAIN:\n",
    "\n",
    "1. ENTRADA (Input) - DicionÃ¡rio simples com os dados de entrada\n",
    "2. PROMPT - Template formatado usando ChatPromptTemplate.from_messages\n",
    "3. MODELO - LLM (Large Language Model) - OpenAI no nosso caso\n",
    "4. PARSER DE SAÃDA - StrOutputParser() ou with_structured_output()\n",
    "\n",
    "ğŸ”— LCEL (LangChain Expression Language):\n",
    "- Sintaxe: input | prompt | llm | output_parser\n",
    "- O operador \"|\" (pipe) conecta os componentes em sequÃªncia\n",
    "- Cada componente processa a saÃ­da do anterior\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b59854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ConfiguraÃ§Ã£o do LLM realizada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "#* --- CÃ‰LULA DE SETUP IDEAL ---\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Desabilita o tracing para manter o output limpo nos exercÃ­cios\n",
    "# Dica: Para depurar chains complexas, mude para \"true\" e configure o LangSmith!\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\n",
    "# Carrega as variÃ¡veis de ambiente do arquivo .env\n",
    "# A funÃ§Ã£o retorna True se encontrou o arquivo, False caso contrÃ¡rio.\n",
    "if not load_dotenv(find_dotenv()):\n",
    "    print(\"Arquivo .env nÃ£o encontrado. Verificando variÃ¡veis de ambiente do sistema.\")\n",
    "\n",
    "# Valida a chave da API e instancia o LLM de forma segura e limpa\n",
    "# O LangChain busca a chave do ambiente automaticamente. NÃ£o Ã© necessÃ¡rio\n",
    "# carregar a chave em uma variÃ¡vel ou passÃ¡-la explicitamente.\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"A variÃ¡vel de ambiente OPENAI_API_KEY nÃ£o foi encontrada.\")\n",
    "\n",
    "# InstanciaÃ§Ã£o simplificada:\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "print(\"âœ… ConfiguraÃ§Ã£o do LLM realizada com sucesso!\")\n",
    "# Para um teste rÃ¡pido, vocÃª pode descomentar a linha abaixo:\n",
    "# print(llm.invoke(\"Diga olÃ¡ em portuguÃªs.\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20778936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import Runnable, RunnableSerializable\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# EXERCÃCIO 1: CHAIN BÃSICA - {'produto': 'cafÃ©} e retorna uma frase de marketing\n",
    "# ===============================================================================\n",
    "# Defina o LLM com um pouco de temperatura para mais criatividade\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "def marketing_chain(llm: ChatOpenAI) -> str:\n",
    "    \"\"\"\n",
    "    Cria uma cadeia simples que gera uma frase de marketing para um produto.\n",
    "\n",
    "    Args:\n",
    "        llm (Runnable): O modelo de linguagem a ser utilizado.\n",
    "\n",
    "    Returns:\n",
    "        str: A frase de marketing gerada pelo modelo.\n",
    "    \"\"\"\n",
    "    # 1. Entrada - DicionÃ¡rio simples\n",
    "    input_data = {\"produto\": \"cafÃ©\"}\n",
    "\n",
    "    # 2. Defina o prompt usando ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"VocÃª Ã© um especialista em marketing.\"),\n",
    "        (\"user\", \"Crie uma frase de marketing para o seguinte produto: {produto}\")\n",
    "    ])\n",
    "\n",
    "    # 3. Defina o parser de saÃ­da\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # 4. Criando a chain com LCEL - Tipagem correta\n",
    "    chain: RunnableSerializable[Dict[str, Any], str] = prompt | llm | parser # type: ignore\n",
    "\n",
    "    # 5. Execute a chain com os dados de entrada\n",
    "    result = chain.invoke(input_data)\n",
    "    print(f\"ğŸ“ Entrada: {input_data['produto']}\")\n",
    "    print(f\"ğŸ”„ Processamento: Prompt â†’ LLM â†’ Parser\")\n",
    "    print(f\"âœ¨ Resultado: {result}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee3c96",
   "metadata": {},
   "source": [
    "### ExercÃ­cio 1:\n",
    "\n",
    "* entrada: `{\"produto\":\"cafÃ©\"}`\n",
    "* output: frase de marketing sobre cafÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9135043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Entrada: cafÃ©\n",
      "ğŸ”„ Processamento: Prompt â†’ LLM â†’ Parser\n",
      "âœ¨ Resultado: \"Desperte seus sentidos com o sabor irresistÃ­vel do nosso cafÃ©: a energia que transforma seu dia em momentos especiais!\"\n"
     ]
    }
   ],
   "source": [
    "marketing_cafÃ© = marketing_chain(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636141d",
   "metadata": {},
   "source": [
    "### ExercÃ­cio 2:\n",
    "\n",
    "* entrada: `{\"palavra\":\"gato\", \"idioma\":\"inglÃªs\"}`\n",
    "* output: traduÃ§Ã£o da palavra de entrada para o idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5595b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# EXERCÃCIO 2: CHAIN BÃSICA - traduÃ§Ã£o de palavras {'palavra': 'gato', 'idioma': 'inglÃªs'}\n",
    "# ===============================================================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "def chain_tradutor(llm: ChatOpenAI) -> str:\n",
    "    \"\"\"\n",
    "    Traduz uma palavra para um idioma especificado usando uma cadeia simples.\n",
    "\n",
    "    Args:\n",
    "        palavra (str): A palavra a ser traduzida.\n",
    "        idioma (str): O idioma para o qual a palavra deve ser traduzida.\n",
    "\n",
    "    Returns:\n",
    "        str: Palavra traduzida na lÃ­ngua especificada.\n",
    "    \"\"\"\n",
    "    # 1. Entrada - DicionÃ¡rio simples\n",
    "    input_data = {\n",
    "        \"palavra\": \"gato\",\n",
    "        \"idioma\": \"inglÃªs\"\n",
    "    }\n",
    "\n",
    "    # 2. Defina o prompt usando ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"VocÃª Ã© um tradutor experiente.\"),\n",
    "        (\"user\", \"Traduza a seguinte palavra: '{palavra}' para {idioma}.\")\n",
    "    ])\n",
    "    # 3. Defina o parser de saÃ­da\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # 4. Criando a chain co LCEL\n",
    "    chain = prompt | llm | parser # type: ignore\n",
    "\n",
    "    # 5. Execute a chain com os dados de entrada\n",
    "    result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "    # Processando saÃ­da\n",
    "    print(f\"ğŸ“ Entrada: {input_data}\")\n",
    "    print(f\"ğŸ”„ Processamento: Prompt â†’ LLM â†’ Parser\")\n",
    "    print(f\"âœ¨ Resultado: {result}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6346c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Entrada: {'palavra': 'gato', 'idioma': 'inglÃªs'}\n",
      "ğŸ”„ Processamento: Prompt â†’ LLM â†’ Parser\n",
      "âœ¨ Resultado: A palavra \"gato\" em inglÃªs Ã© \"cat\".\n"
     ]
    }
   ],
   "source": [
    "traducao_palavra = chain_tradutor(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0bebf",
   "metadata": {},
   "source": [
    "### Escreva uma chain que recebe `{\"palavra\":\"saudade\"}` e retorna a sua definiÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec6b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Entrada: {'palavra': 'saudade'}\n",
      "ğŸ”„ Processamento: Prompt â†’ LLM â†’ Parser\n",
      "âœ¨ Resultado: A palavra \"saudade\" Ã© um termo da lÃ­ngua portuguesa que expressa um sentimento profundo de nostalgia, anseio ou melancolia em relaÃ§Ã£o a algo ou alguÃ©m que estÃ¡ ausente. Ã‰ uma emoÃ§Ã£o complexa que pode envolver a lembranÃ§a de momentos passados, a falta de pessoas queridas, ou atÃ© mesmo a perda de experiÃªncias que foram significativas. A saudade Ã© muitas vezes descrita como uma mistura de tristeza e alegria, pois, embora remeta Ã  ausÃªncia, tambÃ©m evoca memÃ³rias afetivas que trazem um certo conforto. Ã‰ considerada uma palavra intraduzÃ­vel em muitas lÃ­nguas, refletindo uma experiÃªncia emocional Ãºnica da cultura lusÃ³fona.\n"
     ]
    }
   ],
   "source": [
    "# Defina uma chain que recebe {\"palavra\":\"saudade\"} e retorna a sua definiÃ§Ã£o\n",
    "# Definindo uma temperatura intermediÃ¡ria para um equilÃ­brio entre criatividade e precisÃ£o\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# 1. Entrada - DicionÃ¡rio simples\n",
    "input_data = {\"palavra\":\"saudade\"}\n",
    "\n",
    "# 2. Defina o prompt usando ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"VocÃª Ã© um especialista em significado de palavras.\"),\n",
    "        (\"user\", \"Escreva a definiÃ§Ã£o da palavra : {palavra}.\")\n",
    "    ])\n",
    "    # 3. Defina o parser de saÃ­da\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 4. Criando a chain co LCEL\n",
    "chain = prompt | llm | parser # type: ignore\n",
    "\n",
    "# 5. Execute a chain com os dados de entrada\n",
    "result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "# Processando saÃ­da\n",
    "print(f\"ğŸ“ Entrada: {input_data}\")\n",
    "print(f\"ğŸ”„ Processamento: Prompt â†’ LLM â†’ Parser\")\n",
    "print(f\"âœ¨ Resultado: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a254a0",
   "metadata": {},
   "source": [
    "### Uma chain que recebe:\n",
    "\n",
    "`{\"filme\": \"O Poderoso ChefÃ£o\"}` e retorna o nome do diretor (use um Pydantic Model para a saÃ­da)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0577449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Entrada: {'filme': 'O Poderoso ChefÃ£o'}\n",
      "ğŸ”„ Processamento: Prompt â†’ LLM â†’ Parser\n",
      "âœ¨ Resultado: Francis Ford Coppola\n"
     ]
    }
   ],
   "source": [
    "class DirectorMovie(BaseModel):\n",
    "    nome: str = Field(..., description=\"Nome do diretor do filme\")\n",
    "\n",
    "# Modelo de linguagem com temperatura equilibrada para precisÃ£o e criatividade.\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "# 1. Entrada - DicionÃ¡rio simples\n",
    "input_data = {\"filme\": \"O Poderoso ChefÃ£o\"}\n",
    "\n",
    "# 2. Defina o prompt usando ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"VocÃª Ã© um especialista em filmes.\"),\n",
    "        (\"user\", \"Quem Ã© o diretor do filme : {filme}? Responda apenas com o nome.\")\n",
    "    ])\n",
    "# 3. Defina o parser de saÃ­da usando Pydantic\n",
    "llm_structured = llm.with_structured_output(DirectorMovie) # type: ignore\n",
    "\n",
    "# 4. Criando a chain co LCEL\n",
    "chain = prompt | llm_structured # type: ignore\n",
    "\n",
    "# 5. Execute a chain com os dados de entrada\n",
    "result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "# Processando saÃ­da\n",
    "print(f\"ğŸ“ Entrada: {input_data}\")\n",
    "print(f\"ğŸ”„ Processamento: Prompt â†’ LLM â†’ Parser\")\n",
    "print(f\"âœ¨ Resultado: {result.nome}\") #type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcc2973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Entrada: {'produto': 'smartphone', 'marca': 'Apple', 'preco': 'R$ 3.500', 'publico': 'jovens profissionais'}\n",
      "âœ¨ DescriÃ§Ã£o do Produto:\n",
      "**iPhone 14 - A Escolha dos Jovens Profissionais**\n",
      "\n",
      "Descubra o poder e a elegÃ¢ncia do novo **iPhone 14**, a ferramenta perfeita para jovens profissionais que buscam excelÃªncia em cada aspecto de suas vidas. Com um design sofisticado e recursos inovadores, este smartphone nÃ£o Ã© apenas um dispositivo â€“ Ã© uma extensÃ£o do seu estilo de vida.\n",
      "\n",
      "**CaracterÃ­sticas que fazem a diferenÃ§a:**\n",
      "\n",
      "- **Desempenho Excepcional:** Equipado com o chip A15 Bionic, o iPhone 14 oferece velocidade e eficiÃªncia impressionantes. Execute mÃºltiplas tarefas, jogue e utilize aplicativos pesados sem qualquer lentidÃ£o. A produtividade nunca foi tÃ£o fÃ¡cil!\n",
      "\n",
      "- **CÃ¢mera Profissional:** Capture momentos especiais e crie conteÃºdos incrÃ­veis para suas redes sociais com a cÃ¢mera de alta qualidade. Com recursos como Modo Noite e ProRAW, suas fotos e vÃ­deos terÃ£o um toque profissional, prontos para impressionar.\n",
      "\n",
      "- **Display Impressionante:** A tela Super Retina XDR proporciona cores vibrantes e contraste excepcional, ideal para assistir a vÃ­deos, realizar videoconferÃªncias ou simplesmente navegar pela internet com clareza.\n",
      "\n",
      "- **IntegraÃ§Ã£o Perfeita:** Com o ecossistema Apple, vocÃª pode conectar seu iPhone 14 a outros dispositivos da marca, como MacBooks e iPads, tornando sua rotina ainda mais fluida e eficiente.\n",
      "\n",
      "- **SeguranÃ§a e Privacidade:** A Apple prioriza a sua seguranÃ§a. Com o Face ID, suas informaÃ§Ãµes pessoais ficam protegidas, permitindo que vocÃª se concentre no que realmente importa.\n",
      "\n",
      "**Por que escolher o iPhone 14?**\n",
      "\n",
      "Por apenas **R$ 3.500**, vocÃª terÃ¡ em mÃ£os um smartphone que nÃ£o apenas acompanha seu ritmo acelerado, mas tambÃ©m eleva sua imagem profissional. Este Ã© o dispositivo ideal para quem busca nÃ£o apenas tecnologia, mas tambÃ©m estilo e status. \n",
      "\n",
      "Transforme a maneira como vocÃª se conecta, trabalha e se diverte. Adquira agora o seu **iPhone 14** e esteja um passo Ã  frente na era digital!\n"
     ]
    }
   ],
   "source": [
    "def exercicio_2():\n",
    "    \"\"\"\n",
    "    ğŸ“š OBJETIVO: Trabalhar com prompts mais complexos e mÃºltiplas variÃ¡veis\n",
    "    \n",
    "    CONCEITO: Como o LangChain passa dados entre componentes\n",
    "    - O prompt recebe um dicionÃ¡rio e formata as variÃ¡veis\n",
    "    - O LLM recebe o prompt formatado\n",
    "    - O parser limpa a resposta do LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ENTRADA - MÃºltiplas variÃ¡veis\n",
    "    entrada = {\n",
    "        \"produto\": \"smartphone\",\n",
    "        \"marca\": \"Apple\",\n",
    "        \"preco\": \"R$ 3.500\",\n",
    "        \"publico\": \"jovens profissionais\"\n",
    "    }\n",
    "    \n",
    "    # 2. PROMPT - Template mais complexo\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"VocÃª Ã© um especialista em marketing digital.\"),\n",
    "        (\"human\", \"\"\"\n",
    "        Crie uma descriÃ§Ã£o de produto para vendas online:\n",
    "        \n",
    "        Produto: {produto}\n",
    "        Marca: {marca}\n",
    "        PreÃ§o: {preco}\n",
    "        PÃºblico-alvo: {publico}\n",
    "        \n",
    "        A descriÃ§Ã£o deve ser persuasiva e focada no pÃºblico-alvo.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    \n",
    "    # 3. PARSER DE SAÃDA\n",
    "    parser = StrOutputParser()\n",
    "    \n",
    "    # 4. CHAIN\n",
    "    chain = prompt | llm | parser # type: ignore\n",
    "    \n",
    "    # 5. EXECUÃ‡ÃƒO\n",
    "    resultado = chain.invoke(entrada) # type: ignore\n",
    "    \n",
    "    print(f\"ğŸ“ Entrada: {entrada}\")\n",
    "    print(f\"âœ¨ DescriÃ§Ã£o do Produto:\\n{resultado}\")\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "# Executar exercÃ­cio 2\n",
    "resultado_2 = exercicio_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00fd8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸš€ EXERCÃCIO 6: CHAIN COM SAÃDA ESTRUTURADA\n",
      "============================================================\n",
      "ğŸ“ Texto analisado: \n",
      "        Estou absolutamente encantado com este produto! A qualidade superou todas as minhas \n",
      "      ...\n",
      "ğŸ¯ Sentimento: positivo\n",
      "ğŸ“Š ConfianÃ§a: 0.95\n",
      "ğŸ·ï¸  Palavras-chave: ['encantado', 'qualidade', 'atendimento ao cliente', 'entrega rÃ¡pida', 'recomendo', 'comprarei novamente']\n",
      "ğŸ“‹ Resumo: O autor estÃ¡ muito satisfeito com o produto e recomenda a compra.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXERCÃCIO 6: CHAIN COM SAÃDA ESTRUTURADA (PYDANTIC)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ EXERCÃCIO 6: CHAIN COM SAÃDA ESTRUTURADA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def exercicio_6():\n",
    "    \"\"\"\n",
    "    ğŸ“š OBJETIVO: Usar with_structured_output() para dados estruturados\n",
    "\n",
    "    VANTAGEM: Em vez de string livre, obtemos um objeto Python estruturado\n",
    "    - ValidaÃ§Ã£o automÃ¡tica dos dados\n",
    "    - Acesso direto aos campos\n",
    "    - Melhor para integraÃ§Ãµes com outras partes do cÃ³digo\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. MODELO PYDANTIC - Define a estrutura da saÃ­da\n",
    "    class AnaliseTexto(BaseModel):\n",
    "        \"\"\"Modelo para anÃ¡lise estruturada de texto\"\"\"\n",
    "        sentimento: str = Field(description=\"Sentimento: positivo, negativo ou neutro\")\n",
    "        confianca: float = Field(description=\"NÃ­vel de confianÃ§a de 0 a 1\")\n",
    "        palavras_chave: List[str] = Field(description=\"Lista de palavras-chave importantes\")\n",
    "        resumo: str = Field(description=\"Resumo em uma frase\")\n",
    "\n",
    "    # 2. ENTRADA\n",
    "    entrada = {\n",
    "        \"texto\": \"\"\"\n",
    "        Estou absolutamente encantado com este produto! A qualidade superou todas as minhas \n",
    "        expectativas. O atendimento ao cliente foi excepcional, e a entrega foi mais rÃ¡pida \n",
    "        do que prometido. Recomendo fortemente para qualquer pessoa que esteja considerando \n",
    "        esta compra. Definitivamente comprarei novamente!\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # 3. PROMPT\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"VocÃª Ã© um especialista em anÃ¡lise de sentimentos e texto.\"),\n",
    "        (\"human\", \"Analise o seguinte texto: {texto}\")\n",
    "    ])\n",
    "\n",
    "    # 4. LLM COM SAÃDA ESTRUTURADA - Substitui o StrOutputParser\n",
    "    llm_estruturado = llm.with_structured_output(AnaliseTexto) # type: ignore\n",
    "\n",
    "    # 5. CHAIN\n",
    "    chain = prompt | llm_estruturado # type: ignore\n",
    "\n",
    "    # 6. EXECUÃ‡ÃƒO\n",
    "    resultado = chain.invoke(entrada) # type: ignore\n",
    "\n",
    "    print(f\"ğŸ“ Texto analisado: {entrada['texto'][:100]}...\")\n",
    "    print(f\"ğŸ¯ Sentimento: {resultado.sentimento}\")\n",
    "    print(f\"ğŸ“Š ConfianÃ§a: {resultado.confianca}\")\n",
    "    print(f\"ğŸ·ï¸  Palavras-chave: {resultado.palavras_chave}\")\n",
    "    print(f\"ğŸ“‹ Resumo: {resultado.resumo}\")\n",
    "\n",
    "    return resultado # type: ignore\n",
    "\n",
    "# Executar exercÃ­cio 3\n",
    "resultado_6 = exercicio_6() # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
