{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4c01b8",
   "metadata": {},
   "source": [
    "## Exercícios básicos sobre LCEL - LangChain\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd46a2d",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## CONCEITOS FUNDAMENTAIS DO LANGCHAIN\n",
    "## =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "🎯 CORE COMPONENTS DE UMA APLICAÇÃO LANGCHAIN:\n",
    "\n",
    "1. ENTRADA (Input) - Dicionário simples com os dados de entrada\n",
    "2. PROMPT - Template formatado usando ChatPromptTemplate.from_messages\n",
    "3. MODELO - LLM (Large Language Model) - OpenAI no nosso caso\n",
    "4. PARSER DE SAÍDA - StrOutputParser() ou with_structured_output()\n",
    "\n",
    "🔗 LCEL (LangChain Expression Language):\n",
    "- Sintaxe: input | prompt | llm | output_parser\n",
    "- O operador \"|\" (pipe) conecta os componentes em sequência\n",
    "- Cada componente processa a saída do anterior\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b59854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuração do LLM realizada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "#* --- CÉLULA DE SETUP IDEAL ---\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Desabilita o tracing para manter o output limpo nos exercícios\n",
    "# Dica: Para depurar chains complexas, mude para \"true\" e configure o LangSmith!\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\n",
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "# A função retorna True se encontrou o arquivo, False caso contrário.\n",
    "if not load_dotenv(find_dotenv()):\n",
    "    print(\"Arquivo .env não encontrado. Verificando variáveis de ambiente do sistema.\")\n",
    "\n",
    "# Valida a chave da API e instancia o LLM de forma segura e limpa\n",
    "# O LangChain busca a chave do ambiente automaticamente. Não é necessário\n",
    "# carregar a chave em uma variável ou passá-la explicitamente.\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"A variável de ambiente OPENAI_API_KEY não foi encontrada.\")\n",
    "\n",
    "# Instanciação simplificada:\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "print(\"✅ Configuração do LLM realizada com sucesso!\")\n",
    "# Para um teste rápido, você pode descomentar a linha abaixo:\n",
    "# print(llm.invoke(\"Diga olá em português.\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20778936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import Runnable, RunnableSerializable\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "259b19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# EXERCÍCIO 1: CHAIN BÁSICA - {'produto': 'café} e retorna uma frase de marketing\n",
    "# ===============================================================================\n",
    "# Defina o LLM com um pouco de temperatura para mais criatividade\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "def marketing_chain(llm: ChatOpenAI) -> str:\n",
    "    \"\"\"\n",
    "    Cria uma cadeia simples que gera uma frase de marketing para um produto.\n",
    "\n",
    "    Args:\n",
    "        llm (Runnable): O modelo de linguagem a ser utilizado.\n",
    "\n",
    "    Returns:\n",
    "        str: A frase de marketing gerada pelo modelo.\n",
    "    \"\"\"\n",
    "    # 1. Entrada - Dicionário simples\n",
    "    input_data = {\"produto\": \"café\"}\n",
    "\n",
    "    # 2. Defina o prompt usando ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Você é um especialista em marketing.\"),\n",
    "        (\"user\", \"Crie uma frase de marketing para o seguinte produto: {produto}\")\n",
    "    ])\n",
    "\n",
    "    # 3. Defina o parser de saída\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # 4. Criando a chain com LCEL - Tipagem correta\n",
    "    chain: RunnableSerializable[Dict[str, Any], str] = prompt | llm | parser # type: ignore\n",
    "\n",
    "    # 5. Execute a chain com os dados de entrada\n",
    "    result = chain.invoke(input_data)\n",
    "    print(f\"📝 Entrada: {input_data['produto']}\")\n",
    "    print(f\"🔄 Processamento: Prompt → LLM → Parser\")\n",
    "    print(f\"✨ Resultado: {result}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee3c96",
   "metadata": {},
   "source": [
    "### Exercício 1:\n",
    "\n",
    "* entrada: `{\"produto\":\"café\"}`\n",
    "* output: frase de marketing sobre café"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9135043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Entrada: café\n",
      "🔄 Processamento: Prompt → LLM → Parser\n",
      "✨ Resultado: \"Desperte seus sentidos com o nosso café: cada xícara é uma viagem de sabor que transforma seu dia!\"\n"
     ]
    }
   ],
   "source": [
    "marketing_café = marketing_chain(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636141d",
   "metadata": {},
   "source": [
    "### Exercício 2:\n",
    "\n",
    "* entrada: `{\"palavra\":\"gato\", \"idioma\":\"inglês\"}`\n",
    "* output: tradução da palavra de entrada para o idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5595b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# EXERCÍCIO 2: CHAIN BÁSICA - tradução de palavras {'palavra': 'gato', 'idioma': 'inglês'}\n",
    "# ===============================================================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "def chain_tradutor(llm: ChatOpenAI) -> str:\n",
    "    \"\"\"\n",
    "    Traduz uma palavra para um idioma especificado usando uma cadeia simples.\n",
    "\n",
    "    Args:\n",
    "        palavra (str): A palavra a ser traduzida.\n",
    "        idioma (str): O idioma para o qual a palavra deve ser traduzida.\n",
    "\n",
    "    Returns:\n",
    "        str: Palavra traduzida na língua especificada.\n",
    "    \"\"\"\n",
    "    # 1. Entrada - Dicionário simples\n",
    "    input_data = {\n",
    "        \"palavra\": \"gato\",\n",
    "        \"idioma\": \"inglês\"\n",
    "    }\n",
    "\n",
    "    # 2. Defina o prompt usando ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Você é um tradutor experiente.\"),\n",
    "        (\"user\", \"Traduza a seguinte palavra: '{palavra}' para {idioma}.\")\n",
    "    ])\n",
    "    # 3. Defina o parser de saída\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # 4. Criando a chain co LCEL\n",
    "    chain = prompt | llm | parser # type: ignore\n",
    "\n",
    "    # 5. Execute a chain com os dados de entrada\n",
    "    result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "    # Processando saída\n",
    "    print(f\"📝 Entrada: {input_data}\")\n",
    "    print(f\"🔄 Processamento: Prompt → LLM → Parser\")\n",
    "    print(f\"✨ Resultado: {result}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6346c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Entrada: {'palavra': 'gato', 'idioma': 'inglês'}\n",
      "🔄 Processamento: Prompt → LLM → Parser\n",
      "✨ Resultado: A palavra 'gato' em inglês é 'cat'.\n"
     ]
    }
   ],
   "source": [
    "traducao_palavra = chain_tradutor(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0bebf",
   "metadata": {},
   "source": [
    "### Escreva uma chain que recebe `{\"palavra\":\"saudade\"}` e retorna a sua definição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec6b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Entrada: {'palavra': 'saudade'}\n",
      "🔄 Processamento: Prompt → LLM → Parser\n",
      "✨ Resultado: A palavra \"saudade\" é um termo em português que expressa um sentimento profundo de nostalgia e anseio por algo ou alguém que está ausente. É uma mistura de tristeza e carinho, muitas vezes relacionada a memórias afetivas, momentos passados ou pessoas queridas que não estão mais presentes. A saudade é considerada uma emoção complexa, que pode evocar tanto a dor da perda quanto a alegria das lembranças. É um conceito culturalmente significativo em países de língua portuguesa, especialmente no Brasil e em Portugal.\n"
     ]
    }
   ],
   "source": [
    "# Defina uma chain que recebe {\"palavra\":\"saudade\"} e retorna a sua definição\n",
    "# Definindo uma temperatura intermediária para um equilíbrio entre criatividade e precisão\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# 1. Entrada - Dicionário simples\n",
    "input_data = {\"palavra\":\"saudade\"}\n",
    "\n",
    "# 2. Defina o prompt usando ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Você é um especialista em significado de palavras.\"),\n",
    "        (\"user\", \"Escreva a definição da palavra : {palavra}.\")\n",
    "    ])\n",
    "    # 3. Defina o parser de saída\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 4. Criando a chain co LCEL\n",
    "chain = prompt | llm | parser # type: ignore\n",
    "\n",
    "# 5. Execute a chain com os dados de entrada\n",
    "result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "# Processando saída\n",
    "print(f\"📝 Entrada: {input_data}\")\n",
    "print(f\"🔄 Processamento: Prompt → LLM → Parser\")\n",
    "print(f\"✨ Resultado: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a254a0",
   "metadata": {},
   "source": [
    "### Uma chain que recebe:\n",
    "\n",
    "`{\"filme\": \"O Poderoso Chefão\"}` e retorna o nome do diretor (use um Pydantic Model para a saída)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0577449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Entrada: {'filme': 'O Poderoso Chefão'}\n",
      "🔄 Processamento: Prompt → LLM → Parser\n",
      "✨ Resultado: Francis Ford Coppola\n"
     ]
    }
   ],
   "source": [
    "class DirectorMovie(BaseModel):\n",
    "    nome: str = Field(..., description=\"Nome do diretor do filme\")\n",
    "\n",
    "# Modelo de linguagem com temperatura equilibrada para precisão e criatividade.\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "# 1. Entrada - Dicionário simples\n",
    "input_data = {\"filme\": \"O Poderoso Chefão\"}\n",
    "\n",
    "# 2. Defina o prompt usando ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Você é um especialista em filmes.\"),\n",
    "        (\"user\", \"Quem é o diretor do filme : {filme}? Responda apenas com o nome.\")\n",
    "    ])\n",
    "# 3. Defina o parser de saída usando Pydantic\n",
    "llm_structured = llm.with_structured_output(DirectorMovie) # type: ignore\n",
    "\n",
    "# 4. Criando a chain co LCEL\n",
    "chain = prompt | llm_structured # type: ignore\n",
    "\n",
    "# 5. Execute a chain com os dados de entrada\n",
    "result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "# Processando saída\n",
    "print(f\"📝 Entrada: {input_data}\")\n",
    "print(f\"🔄 Processamento: Prompt → LLM → Parser\")\n",
    "print(f\"✨ Resultado: {result.nome}\") #type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcc2973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Entrada: json.dumps({'produto': 'smartphone', 'marca': 'Apple', 'preco': 'R$ 3.500', 'publico': 'jovens profissionais'}, indent=4)\n",
      "✨ Descrição do Produto:\n",
      "**Apple iPhone - A Revolução em Suas Mãos**\n",
      "\n",
      "Descubra o novo iPhone, o smartphone que redefine o que significa estar conectado. Com um design elegante e sofisticado, este dispositivo é mais do que um celular; é uma extensão do seu estilo de vida moderno. \n",
      "\n",
      "**Por que escolher o iPhone?**\n",
      "\n",
      "- **Desempenho Inigualável:** Equipado com o avançado chip A15 Bionic, o iPhone oferece velocidade e eficiência impressionantes, permitindo que você execute várias tarefas com facilidade. Desde videoconferências até jogos intensivos, tudo acontece de forma fluida e rápida.\n",
      "\n",
      "- **Câmera Profissional:** Capture cada momento com a precisão de uma câmera profissional. Com um sistema de câmeras duplas e recursos como Modo Noite e Deep Fusion, suas fotos e vídeos ganharão vida, mesmo em condições de pouca luz. Perfeito para jovens profissionais que desejam impressionar nas redes sociais ou documentar suas conquistas.\n",
      "\n",
      "- **Integração Perfeita:** O ecossistema Apple foi projetado para funcionar em harmonia. Sincronize seus dispositivos, compartilhe arquivos com facilidade e acesse suas aplicações favoritas em qualquer lugar. A produtividade nunca foi tão simples.\n",
      "\n",
      "- **Segurança e Privacidade:** Com a Apple, sua segurança é prioridade. O iPhone vem com recursos avançados de proteção de dados, garantindo que suas informações pessoais permaneçam seguras.\n",
      "\n",
      "- **Design que Impressiona:** Com um acabamento premium e uma tela Super Retina XDR, o iPhone não é apenas um dispositivo; é uma declaração de estilo. Leve-o para reuniões, eventos ou encontros, e destaque-se com um produto que reflete seu sucesso.\n",
      "\n",
      "**Por que esperar?** Por apenas R$ 3.500, você pode ter em mãos o smartphone que combina tecnologia de ponta, design sofisticado e funcionalidades que atendem às suas necessidades diárias. \n",
      "\n",
      "Transforme sua forma de se conectar, trabalhar e viver. Adquira seu iPhone hoje mesmo e leve sua experiência digital para o próximo nível!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def exercicio_2():\n",
    "    \"\"\"\n",
    "    📚 OBJETIVO: Trabalhar com prompts mais complexos e múltiplas variáveis\n",
    "    \n",
    "    CONCEITO: Como o LangChain passa dados entre componentes\n",
    "    - O prompt recebe um dicionário e formata as variáveis\n",
    "    - O LLM recebe o prompt formatado\n",
    "    - O parser limpa a resposta do LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ENTRADA - Múltiplas variáveis\n",
    "    entrada = {\n",
    "        \"produto\": \"smartphone\",\n",
    "        \"marca\": \"Apple\",\n",
    "        \"preco\": \"R$ 3.500\",\n",
    "        \"publico\": \"jovens profissionais\"\n",
    "    }\n",
    "    \n",
    "    # 2. PROMPT - Template mais complexo\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Você é um especialista em marketing digital.\"),\n",
    "        (\"human\", \"\"\"\n",
    "        Crie uma descrição de produto para vendas online:\n",
    "        \n",
    "        Produto: {produto}\n",
    "        Marca: {marca}\n",
    "        Preço: {preco}\n",
    "        Público-alvo: {publico}\n",
    "        \n",
    "        A descrição deve ser persuasiva e focada no público-alvo.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    \n",
    "    # 3. PARSER DE SAÍDA\n",
    "    parser = StrOutputParser()\n",
    "    \n",
    "    # 4. CHAIN\n",
    "    chain = prompt | llm | parser # type: ignore\n",
    "    \n",
    "    # 5. EXECUÇÃO\n",
    "    resultado = chain.invoke(entrada) # type: ignore\n",
    "    \n",
    "    print(f\"📝 Entrada: json.dumps({entrada}, indent=4)\")\n",
    "    print(f\"✨ Descrição do Produto:\\n{resultado}\")\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "# Executar exercício 2\n",
    "resultado_2 = exercicio_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00fd8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🚀 EXERCÍCIO 6: CHAIN COM SAÍDA ESTRUTURADA\n",
      "============================================================\n",
      "📝 Texto analisado: \n",
      "        Estou absolutamente encantado com este produto! A qualidade superou todas as minhas \n",
      "      ...\n",
      "🎯 Sentimento: positivo\n",
      "📊 Confiança: 0.95\n",
      "🏷️  Palavras-chave: ['encantado', 'qualidade', 'atendimento ao cliente', 'entrega rápida', 'recomendo', 'comprarei novamente']\n",
      "📋 Resumo: O autor está extremamente satisfeito com o produto e recomenda a compra.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXERCÍCIO 6: CHAIN COM SAÍDA ESTRUTURADA (PYDANTIC)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🚀 EXERCÍCIO 6: CHAIN COM SAÍDA ESTRUTURADA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def exercicio_6() -> None:\n",
    "    \"\"\"\n",
    "    📚 OBJETIVO: Usar with_structured_output() para dados estruturados\n",
    "\n",
    "    VANTAGEM: Em vez de string livre, obtemos um objeto Python estruturado\n",
    "    - Validação automática dos dados\n",
    "    - Acesso direto aos campos\n",
    "    - Melhor para integrações com outras partes do código\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. MODELO PYDANTIC - Define a estrutura da saída\n",
    "    class AnaliseTexto(BaseModel):\n",
    "        \"\"\"Modelo para análise estruturada de texto\"\"\"\n",
    "        sentimento: str = Field(description=\"Sentimento: positivo, negativo ou neutro\")\n",
    "        confianca: float = Field(description=\"Nível de confiança de 0 a 1\")\n",
    "        palavras_chave: List[str] = Field(description=\"Lista de palavras-chave importantes\")\n",
    "        resumo: str = Field(description=\"Resumo em uma frase\")\n",
    "\n",
    "    # 2. ENTRADA\n",
    "    entrada = {\n",
    "        \"texto\": \"\"\"\n",
    "        Estou absolutamente encantado com este produto! A qualidade superou todas as minhas \n",
    "        expectativas. O atendimento ao cliente foi excepcional, e a entrega foi mais rápida \n",
    "        do que prometido. Recomendo fortemente para qualquer pessoa que esteja considerando \n",
    "        esta compra. Definitivamente comprarei novamente!\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # 3. PROMPT\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Você é um especialista em análise de sentimentos e texto.\"),\n",
    "        (\"human\", \"Analise o seguinte texto: {texto}\")\n",
    "    ])\n",
    "\n",
    "    # 4. LLM COM SAÍDA ESTRUTURADA - Substitui o StrOutputParser\n",
    "    llm_estruturado = llm.with_structured_output(AnaliseTexto) # type: ignore\n",
    "\n",
    "    # 5. CHAIN\n",
    "    chain = prompt | llm_estruturado # type: ignore\n",
    "\n",
    "    # 6. EXECUÇÃO\n",
    "    resultado = chain.invoke(entrada) # type: ignore\n",
    "\n",
    "    print(f\"📝 Texto analisado: {entrada['texto'][:100]}...\")\n",
    "    print(f\"🎯 Sentimento: {resultado.sentimento}\")\n",
    "    print(f\"📊 Confiança: {resultado.confianca}\")\n",
    "    print(f\"🏷️  Palavras-chave: {resultado.palavras_chave}\")\n",
    "    print(f\"📋 Resumo: {resultado.resumo}\")\n",
    "\n",
    "    return resultado # type: ignore\n",
    "\n",
    "# Executar exercício 3\n",
    "resultado_6 = exercicio_6() # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
