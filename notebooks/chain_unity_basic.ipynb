{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4c01b8",
   "metadata": {},
   "source": [
    "## Exerc√≠cios b√°sicos sobre LCEL - LangChain\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd46a2d",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## CONCEITOS FUNDAMENTAIS DO LANGCHAIN\n",
    "## =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "üéØ CORE COMPONENTS DE UMA APLICA√á√ÉO LANGCHAIN:\n",
    "\n",
    "1. ENTRADA (Input) - Dicion√°rio simples com os dados de entrada\n",
    "2. PROMPT - Template formatado usando ChatPromptTemplate.from_messages\n",
    "3. MODELO - LLM (Large Language Model) - OpenAI no nosso caso\n",
    "4. PARSER DE SA√çDA - StrOutputParser() ou with_structured_output()\n",
    "\n",
    "üîó LCEL (LangChain Expression Language):\n",
    "- Sintaxe: input | prompt | llm | output_parser\n",
    "- O operador \"|\" (pipe) conecta os componentes em sequ√™ncia\n",
    "- Cada componente processa a sa√≠da do anterior\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b59854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configura√ß√£o do LLM realizada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "#* --- C√âLULA DE SETUP IDEAL ---\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Desabilita o tracing para manter o output limpo nos exerc√≠cios\n",
    "# Dica: Para depurar chains complexas, mude para \"true\" e configure o LangSmith!\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\n",
    "# Carrega as vari√°veis de ambiente do arquivo .env\n",
    "# A fun√ß√£o retorna True se encontrou o arquivo, False caso contr√°rio.\n",
    "if not load_dotenv(find_dotenv()):\n",
    "    print(\"Arquivo .env n√£o encontrado. Verificando vari√°veis de ambiente do sistema.\")\n",
    "\n",
    "# Valida a chave da API e instancia o LLM de forma segura e limpa\n",
    "# O LangChain busca a chave do ambiente automaticamente. N√£o √© necess√°rio\n",
    "# carregar a chave em uma vari√°vel ou pass√°-la explicitamente.\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"A vari√°vel de ambiente OPENAI_API_KEY n√£o foi encontrada.\")\n",
    "\n",
    "# Instancia√ß√£o simplificada:\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "print(\"‚úÖ Configura√ß√£o do LLM realizada com sucesso!\")\n",
    "# Para um teste r√°pido, voc√™ pode descomentar a linha abaixo:\n",
    "# print(llm.invoke(\"Diga ol√° em portugu√™s.\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20778936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import Runnable, RunnableSerializable\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "259b19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# EXERC√çCIO 1: CHAIN B√ÅSICA - {'produto': 'caf√©} e retorna uma frase de marketing\n",
    "# ===============================================================================\n",
    "# Defina o LLM com um pouco de temperatura para mais criatividade\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "def marketing_chain(llm: ChatOpenAI) -> str:\n",
    "    \"\"\"\n",
    "    Cria uma cadeia simples que gera uma frase de marketing para um produto.\n",
    "\n",
    "    Args:\n",
    "        llm (Runnable): O modelo de linguagem a ser utilizado.\n",
    "\n",
    "    Returns:\n",
    "        str: A frase de marketing gerada pelo modelo.\n",
    "    \"\"\"\n",
    "    # 1. Entrada - Dicion√°rio simples\n",
    "    input_data = {\"produto\": \"caf√©\"}\n",
    "\n",
    "    # 2. Defina o prompt usando ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em marketing.\"),\n",
    "        (\"user\", \"Crie uma frase de marketing para o seguinte produto: {produto}\")\n",
    "    ])\n",
    "\n",
    "    # 3. Defina o parser de sa√≠da\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # 4. Criando a chain com LCEL - Tipagem correta\n",
    "    chain: RunnableSerializable[Dict[str, Any], str] = prompt | llm | parser # type: ignore\n",
    "\n",
    "    # 5. Execute a chain com os dados de entrada\n",
    "    result = chain.invoke(input_data)\n",
    "    print(f\"üìù Entrada: {input_data['produto']}\")\n",
    "    print(f\"üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\")\n",
    "    print(f\"‚ú® Resultado: {result}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee3c96",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 1:\n",
    "\n",
    "* entrada: `{\"produto\":\"caf√©\"}`\n",
    "* output: frase de marketing sobre caf√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9135043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Entrada: caf√©\n",
      "üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\n",
      "‚ú® Resultado: \"Desperte seus sentidos com o nosso caf√©: cada x√≠cara √© uma viagem de sabor que transforma seu dia!\"\n"
     ]
    }
   ],
   "source": [
    "marketing_caf√© = marketing_chain(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636141d",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 2:\n",
    "\n",
    "* entrada: `{\"palavra\":\"gato\", \"idioma\":\"ingl√™s\"}`\n",
    "* output: tradu√ß√£o da palavra de entrada para o idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5595b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# EXERC√çCIO 2: CHAIN B√ÅSICA - tradu√ß√£o de palavras {'palavra': 'gato', 'idioma': 'ingl√™s'}\n",
    "# ===============================================================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "def chain_tradutor(llm: ChatOpenAI) -> str:\n",
    "    \"\"\"\n",
    "    Traduz uma palavra para um idioma especificado usando uma cadeia simples.\n",
    "\n",
    "    Args:\n",
    "        palavra (str): A palavra a ser traduzida.\n",
    "        idioma (str): O idioma para o qual a palavra deve ser traduzida.\n",
    "\n",
    "    Returns:\n",
    "        str: Palavra traduzida na l√≠ngua especificada.\n",
    "    \"\"\"\n",
    "    # 1. Entrada - Dicion√°rio simples\n",
    "    input_data = {\n",
    "        \"palavra\": \"gato\",\n",
    "        \"idioma\": \"ingl√™s\"\n",
    "    }\n",
    "\n",
    "    # 2. Defina o prompt usando ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um tradutor experiente.\"),\n",
    "        (\"user\", \"Traduza a seguinte palavra: '{palavra}' para {idioma}.\")\n",
    "    ])\n",
    "    # 3. Defina o parser de sa√≠da\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # 4. Criando a chain co LCEL\n",
    "    chain = prompt | llm | parser # type: ignore\n",
    "\n",
    "    # 5. Execute a chain com os dados de entrada\n",
    "    result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "    # Processando sa√≠da\n",
    "    print(f\"üìù Entrada: {input_data}\")\n",
    "    print(f\"üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\")\n",
    "    print(f\"‚ú® Resultado: {result}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6346c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Entrada: {'palavra': 'gato', 'idioma': 'ingl√™s'}\n",
      "üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\n",
      "‚ú® Resultado: A palavra 'gato' em ingl√™s √© 'cat'.\n"
     ]
    }
   ],
   "source": [
    "traducao_palavra = chain_tradutor(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0bebf",
   "metadata": {},
   "source": [
    "### Escreva uma chain que recebe `{\"palavra\":\"saudade\"}` e retorna a sua defini√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec6b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Entrada: {'palavra': 'saudade'}\n",
      "üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\n",
      "‚ú® Resultado: A palavra \"saudade\" √© um termo em portugu√™s que expressa um sentimento profundo de nostalgia e anseio por algo ou algu√©m que est√° ausente. √â uma mistura de tristeza e carinho, muitas vezes relacionada a mem√≥rias afetivas, momentos passados ou pessoas queridas que n√£o est√£o mais presentes. A saudade √© considerada uma emo√ß√£o complexa, que pode evocar tanto a dor da perda quanto a alegria das lembran√ßas. √â um conceito culturalmente significativo em pa√≠ses de l√≠ngua portuguesa, especialmente no Brasil e em Portugal.\n"
     ]
    }
   ],
   "source": [
    "# Defina uma chain que recebe {\"palavra\":\"saudade\"} e retorna a sua defini√ß√£o\n",
    "# Definindo uma temperatura intermedi√°ria para um equil√≠brio entre criatividade e precis√£o\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# 1. Entrada - Dicion√°rio simples\n",
    "input_data = {\"palavra\":\"saudade\"}\n",
    "\n",
    "# 2. Defina o prompt usando ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em significado de palavras.\"),\n",
    "        (\"user\", \"Escreva a defini√ß√£o da palavra : {palavra}.\")\n",
    "    ])\n",
    "    # 3. Defina o parser de sa√≠da\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 4. Criando a chain co LCEL\n",
    "chain = prompt | llm | parser # type: ignore\n",
    "\n",
    "# 5. Execute a chain com os dados de entrada\n",
    "result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "# Processando sa√≠da\n",
    "print(f\"üìù Entrada: {input_data}\")\n",
    "print(f\"üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\")\n",
    "print(f\"‚ú® Resultado: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a254a0",
   "metadata": {},
   "source": [
    "### Uma chain que recebe:\n",
    "\n",
    "`{\"filme\": \"O Poderoso Chef√£o\"}` e retorna o nome do diretor (use um Pydantic Model para a sa√≠da)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0577449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Entrada: {'filme': 'O Poderoso Chef√£o'}\n",
      "üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\n",
      "‚ú® Resultado: Francis Ford Coppola\n"
     ]
    }
   ],
   "source": [
    "class DirectorMovie(BaseModel):\n",
    "    nome: str = Field(..., description=\"Nome do diretor do filme\")\n",
    "\n",
    "# Modelo de linguagem com temperatura equilibrada para precis√£o e criatividade.\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "# 1. Entrada - Dicion√°rio simples\n",
    "input_data = {\"filme\": \"O Poderoso Chef√£o\"}\n",
    "\n",
    "# 2. Defina o prompt usando ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em filmes.\"),\n",
    "        (\"user\", \"Quem √© o diretor do filme : {filme}? Responda apenas com o nome.\")\n",
    "    ])\n",
    "# 3. Defina o parser de sa√≠da usando Pydantic\n",
    "llm_structured = llm.with_structured_output(DirectorMovie) # type: ignore\n",
    "\n",
    "# 4. Criando a chain co LCEL\n",
    "chain = prompt | llm_structured # type: ignore\n",
    "\n",
    "# 5. Execute a chain com os dados de entrada\n",
    "result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "# Processando sa√≠da\n",
    "print(f\"üìù Entrada: {input_data}\")\n",
    "print(f\"üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\")\n",
    "print(f\"‚ú® Resultado: {result.nome}\") #type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcc2973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Entrada: json.dumps({'produto': 'smartphone', 'marca': 'Apple', 'preco': 'R$ 3.500', 'publico': 'jovens profissionais'}, indent=4)\n",
      "‚ú® Descri√ß√£o do Produto:\n",
      "**Apple iPhone - A Revolu√ß√£o em Suas M√£os**\n",
      "\n",
      "Descubra o novo iPhone, o smartphone que redefine o que significa estar conectado. Com um design elegante e sofisticado, este dispositivo √© mais do que um celular; √© uma extens√£o do seu estilo de vida moderno. \n",
      "\n",
      "**Por que escolher o iPhone?**\n",
      "\n",
      "- **Desempenho Inigual√°vel:** Equipado com o avan√ßado chip A15 Bionic, o iPhone oferece velocidade e efici√™ncia impressionantes, permitindo que voc√™ execute v√°rias tarefas com facilidade. Desde videoconfer√™ncias at√© jogos intensivos, tudo acontece de forma fluida e r√°pida.\n",
      "\n",
      "- **C√¢mera Profissional:** Capture cada momento com a precis√£o de uma c√¢mera profissional. Com um sistema de c√¢meras duplas e recursos como Modo Noite e Deep Fusion, suas fotos e v√≠deos ganhar√£o vida, mesmo em condi√ß√µes de pouca luz. Perfeito para jovens profissionais que desejam impressionar nas redes sociais ou documentar suas conquistas.\n",
      "\n",
      "- **Integra√ß√£o Perfeita:** O ecossistema Apple foi projetado para funcionar em harmonia. Sincronize seus dispositivos, compartilhe arquivos com facilidade e acesse suas aplica√ß√µes favoritas em qualquer lugar. A produtividade nunca foi t√£o simples.\n",
      "\n",
      "- **Seguran√ßa e Privacidade:** Com a Apple, sua seguran√ßa √© prioridade. O iPhone vem com recursos avan√ßados de prote√ß√£o de dados, garantindo que suas informa√ß√µes pessoais permane√ßam seguras.\n",
      "\n",
      "- **Design que Impressiona:** Com um acabamento premium e uma tela Super Retina XDR, o iPhone n√£o √© apenas um dispositivo; √© uma declara√ß√£o de estilo. Leve-o para reuni√µes, eventos ou encontros, e destaque-se com um produto que reflete seu sucesso.\n",
      "\n",
      "**Por que esperar?** Por apenas R$ 3.500, voc√™ pode ter em m√£os o smartphone que combina tecnologia de ponta, design sofisticado e funcionalidades que atendem √†s suas necessidades di√°rias. \n",
      "\n",
      "Transforme sua forma de se conectar, trabalhar e viver. Adquira seu iPhone hoje mesmo e leve sua experi√™ncia digital para o pr√≥ximo n√≠vel!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def exercicio_2():\n",
    "    \"\"\"\n",
    "    üìö OBJETIVO: Trabalhar com prompts mais complexos e m√∫ltiplas vari√°veis\n",
    "    \n",
    "    CONCEITO: Como o LangChain passa dados entre componentes\n",
    "    - O prompt recebe um dicion√°rio e formata as vari√°veis\n",
    "    - O LLM recebe o prompt formatado\n",
    "    - O parser limpa a resposta do LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ENTRADA - M√∫ltiplas vari√°veis\n",
    "    entrada = {\n",
    "        \"produto\": \"smartphone\",\n",
    "        \"marca\": \"Apple\",\n",
    "        \"preco\": \"R$ 3.500\",\n",
    "        \"publico\": \"jovens profissionais\"\n",
    "    }\n",
    "    \n",
    "    # 2. PROMPT - Template mais complexo\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em marketing digital.\"),\n",
    "        (\"human\", \"\"\"\n",
    "        Crie uma descri√ß√£o de produto para vendas online:\n",
    "        \n",
    "        Produto: {produto}\n",
    "        Marca: {marca}\n",
    "        Pre√ßo: {preco}\n",
    "        P√∫blico-alvo: {publico}\n",
    "        \n",
    "        A descri√ß√£o deve ser persuasiva e focada no p√∫blico-alvo.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    \n",
    "    # 3. PARSER DE SA√çDA\n",
    "    parser = StrOutputParser()\n",
    "    \n",
    "    # 4. CHAIN\n",
    "    chain = prompt | llm | parser # type: ignore\n",
    "    \n",
    "    # 5. EXECU√á√ÉO\n",
    "    resultado = chain.invoke(entrada) # type: ignore\n",
    "    \n",
    "    print(f\"üìù Entrada: json.dumps({entrada}, indent=4)\")\n",
    "    print(f\"‚ú® Descri√ß√£o do Produto:\\n{resultado}\")\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "# Executar exerc√≠cio 2\n",
    "resultado_2 = exercicio_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00fd8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ EXERC√çCIO 6: CHAIN COM SA√çDA ESTRUTURADA\n",
      "============================================================\n",
      "üìù Texto analisado: \n",
      "        Estou absolutamente encantado com este produto! A qualidade superou todas as minhas \n",
      "      ...\n",
      "üéØ Sentimento: positivo\n",
      "üìä Confian√ßa: 0.95\n",
      "üè∑Ô∏è  Palavras-chave: ['encantado', 'qualidade', 'atendimento ao cliente', 'entrega r√°pida', 'recomendo', 'comprarei novamente']\n",
      "üìã Resumo: O autor est√° extremamente satisfeito com o produto e recomenda a compra.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXERC√çCIO 6: CHAIN COM SA√çDA ESTRUTURADA (PYDANTIC)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ EXERC√çCIO 6: CHAIN COM SA√çDA ESTRUTURADA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def exercicio_6() -> None:\n",
    "    \"\"\"\n",
    "    üìö OBJETIVO: Usar with_structured_output() para dados estruturados\n",
    "\n",
    "    VANTAGEM: Em vez de string livre, obtemos um objeto Python estruturado\n",
    "    - Valida√ß√£o autom√°tica dos dados\n",
    "    - Acesso direto aos campos\n",
    "    - Melhor para integra√ß√µes com outras partes do c√≥digo\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. MODELO PYDANTIC - Define a estrutura da sa√≠da\n",
    "    class AnaliseTexto(BaseModel):\n",
    "        \"\"\"Modelo para an√°lise estruturada de texto\"\"\"\n",
    "        sentimento: str = Field(description=\"Sentimento: positivo, negativo ou neutro\")\n",
    "        confianca: float = Field(description=\"N√≠vel de confian√ßa de 0 a 1\")\n",
    "        palavras_chave: List[str] = Field(description=\"Lista de palavras-chave importantes\")\n",
    "        resumo: str = Field(description=\"Resumo em uma frase\")\n",
    "\n",
    "    # 2. ENTRADA\n",
    "    entrada = {\n",
    "        \"texto\": \"\"\"\n",
    "        Estou absolutamente encantado com este produto! A qualidade superou todas as minhas \n",
    "        expectativas. O atendimento ao cliente foi excepcional, e a entrega foi mais r√°pida \n",
    "        do que prometido. Recomendo fortemente para qualquer pessoa que esteja considerando \n",
    "        esta compra. Definitivamente comprarei novamente!\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # 3. PROMPT\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em an√°lise de sentimentos e texto.\"),\n",
    "        (\"human\", \"Analise o seguinte texto: {texto}\")\n",
    "    ])\n",
    "\n",
    "    # 4. LLM COM SA√çDA ESTRUTURADA - Substitui o StrOutputParser\n",
    "    llm_estruturado = llm.with_structured_output(AnaliseTexto) # type: ignore\n",
    "\n",
    "    # 5. CHAIN\n",
    "    chain = prompt | llm_estruturado # type: ignore\n",
    "\n",
    "    # 6. EXECU√á√ÉO\n",
    "    resultado = chain.invoke(entrada) # type: ignore\n",
    "\n",
    "    print(f\"üìù Texto analisado: {entrada['texto'][:100]}...\")\n",
    "    print(f\"üéØ Sentimento: {resultado.sentimento}\")\n",
    "    print(f\"üìä Confian√ßa: {resultado.confianca}\")\n",
    "    print(f\"üè∑Ô∏è  Palavras-chave: {resultado.palavras_chave}\")\n",
    "    print(f\"üìã Resumo: {resultado.resumo}\")\n",
    "\n",
    "    return resultado # type: ignore\n",
    "\n",
    "# Executar exerc√≠cio 3\n",
    "resultado_6 = exercicio_6() # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
