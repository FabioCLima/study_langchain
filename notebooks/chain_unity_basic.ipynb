{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4c01b8",
   "metadata": {},
   "source": [
    "## Exerc√≠cios b√°sicos sobre LCEL - LangChain\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd46a2d",
   "metadata": {},
   "source": [
    "## =============================================================================\n",
    "## CONCEITOS FUNDAMENTAIS DO LANGCHAIN\n",
    "## =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "üéØ CORE COMPONENTS DE UMA APLICA√á√ÉO LANGCHAIN:\n",
    "\n",
    "1. ENTRADA (Input) - Dicion√°rio simples com os dados de entrada\n",
    "2. PROMPT - Template formatado usando ChatPromptTemplate.from_messages\n",
    "3. MODELO - LLM (Large Language Model) - OpenAI no nosso caso\n",
    "4. PARSER DE SA√çDA - StrOutputParser() ou with_structured_output()\n",
    "\n",
    "üîó LCEL (LangChain Expression Language):\n",
    "- Sintaxe: input | prompt | llm | output_parser\n",
    "- O operador \"|\" (pipe) conecta os componentes em sequ√™ncia\n",
    "- Cada componente processa a sa√≠da do anterior\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b59854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#* --- C√âLULA DE SETUP IDEAL ---\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Desabilita o tracing para manter o output limpo nos exerc√≠cios\n",
    "# Dica: Para depurar chains complexas, mude para \"true\" e configure o LangSmith!\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\n",
    "# Carrega as vari√°veis de ambiente do arquivo .env\n",
    "# A fun√ß√£o retorna True se encontrou o arquivo, False caso contr√°rio.\n",
    "if not load_dotenv(find_dotenv()):\n",
    "    print(\"Arquivo .env n√£o encontrado. Verificando vari√°veis de ambiente do sistema.\")\n",
    "\n",
    "# Valida a chave da API e instancia o LLM de forma segura e limpa\n",
    "# O LangChain busca a chave do ambiente automaticamente. N√£o √© necess√°rio\n",
    "# carregar a chave em uma vari√°vel ou pass√°-la explicitamente.\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"A vari√°vel de ambiente OPENAI_API_KEY n√£o foi encontrada.\")\n",
    "\n",
    "# Instancia√ß√£o simplificada:\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "print(\"‚úÖ Configura√ß√£o do LLM realizada com sucesso!\")\n",
    "# Para um teste r√°pido, voc√™ pode descomentar a linha abaixo:\n",
    "# print(llm.invoke(\"Diga ol√° em portugu√™s.\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20778936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import Runnable, RunnableSerializable\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# EXERC√çCIO 1: CHAIN B√ÅSICA - {'produto': 'caf√©} e retorna uma frase de marketing\n",
    "# ===============================================================================\n",
    "# Defina o LLM com um pouco de temperatura para mais criatividade\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "def marketing_chain(llm: ChatOpenAI) -> str:\n",
    "    \"\"\"\n",
    "    Cria uma cadeia simples que gera uma frase de marketing para um produto.\n",
    "\n",
    "    Args:\n",
    "        llm (Runnable): O modelo de linguagem a ser utilizado.\n",
    "\n",
    "    Returns:\n",
    "        str: A frase de marketing gerada pelo modelo.\n",
    "    \"\"\"\n",
    "    # 1. Entrada - Dicion√°rio simples\n",
    "    input_data = {\"produto\": \"caf√©\"}\n",
    "\n",
    "    # 2. Defina o prompt usando ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em marketing.\"),\n",
    "        (\"user\", \"Crie uma frase de marketing para o seguinte produto: {produto}\")\n",
    "    ])\n",
    "\n",
    "    # 3. Defina o parser de sa√≠da\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # 4. Criando a chain com LCEL - Tipagem correta\n",
    "    chain: RunnableSerializable[Dict[str, Any], str] = prompt | llm | parser # type: ignore\n",
    "\n",
    "    # 5. Execute a chain com os dados de entrada\n",
    "    result = chain.invoke(input_data)\n",
    "    print(f\"üìù Entrada: {input_data['produto']}\")\n",
    "    print(f\"üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\")\n",
    "    print(f\"‚ú® Resultado: {result}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee3c96",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 1:\n",
    "\n",
    "* entrada: `{\"produto\":\"caf√©\"}`\n",
    "* output: frase de marketing sobre caf√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_caf√© = marketing_chain(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636141d",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 2:\n",
    "\n",
    "* entrada: `{\"palavra\":\"gato\", \"idioma\":\"ingl√™s\"}`\n",
    "* output: tradu√ß√£o da palavra de entrada para o idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5595b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# EXERC√çCIO 2: CHAIN B√ÅSICA - tradu√ß√£o de palavras {'palavra': 'gato', 'idioma': 'ingl√™s'}\n",
    "# ===============================================================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "def chain_tradutor(llm: ChatOpenAI) -> str:\n",
    "    \"\"\"\n",
    "    Traduz uma palavra para um idioma especificado usando uma cadeia simples.\n",
    "\n",
    "    Args:\n",
    "        palavra (str): A palavra a ser traduzida.\n",
    "        idioma (str): O idioma para o qual a palavra deve ser traduzida.\n",
    "\n",
    "    Returns:\n",
    "        str: Palavra traduzida na l√≠ngua especificada.\n",
    "    \"\"\"\n",
    "    # 1. Entrada - Dicion√°rio simples\n",
    "    input_data = {\n",
    "        \"palavra\": \"gato\",\n",
    "        \"idioma\": \"ingl√™s\"\n",
    "    }\n",
    "\n",
    "    # 2. Defina o prompt usando ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um tradutor experiente.\"),\n",
    "        (\"user\", \"Traduza a seguinte palavra: '{palavra}' para {idioma}.\")\n",
    "    ])\n",
    "    # 3. Defina o parser de sa√≠da\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # 4. Criando a chain co LCEL\n",
    "    chain = prompt | llm | parser # type: ignore\n",
    "\n",
    "    # 5. Execute a chain com os dados de entrada\n",
    "    result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "    # Processando sa√≠da\n",
    "    print(f\"üìù Entrada: {input_data}\")\n",
    "    print(f\"üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\")\n",
    "    print(f\"‚ú® Resultado: {result}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traducao_palavra = chain_tradutor(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0bebf",
   "metadata": {},
   "source": [
    "### Escreva uma chain que recebe `{\"palavra\":\"saudade\"}` e retorna a sua defini√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec6b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina uma chain que recebe {\"palavra\":\"saudade\"} e retorna a sua defini√ß√£o\n",
    "# Definindo uma temperatura intermedi√°ria para um equil√≠brio entre criatividade e precis√£o\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# 1. Entrada - Dicion√°rio simples\n",
    "input_data = {\"palavra\":\"saudade\"}\n",
    "\n",
    "# 2. Defina o prompt usando ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em significado de palavras.\"),\n",
    "        (\"user\", \"Escreva a defini√ß√£o da palavra : {palavra}.\")\n",
    "    ])\n",
    "    # 3. Defina o parser de sa√≠da\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 4. Criando a chain co LCEL\n",
    "chain = prompt | llm | parser # type: ignore\n",
    "\n",
    "# 5. Execute a chain com os dados de entrada\n",
    "result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "# Processando sa√≠da\n",
    "print(f\"üìù Entrada: {input_data}\")\n",
    "print(f\"üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\")\n",
    "print(f\"‚ú® Resultado: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a254a0",
   "metadata": {},
   "source": [
    "### Uma chain que recebe:\n",
    "\n",
    "`{\"filme\": \"O Poderoso Chef√£o\"}` e retorna o nome do diretor (use um Pydantic Model para a sa√≠da)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0577449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectorMovie(BaseModel):\n",
    "    nome: str = Field(..., description=\"Nome do diretor do filme\")\n",
    "\n",
    "# Modelo de linguagem com temperatura equilibrada para precis√£o e criatividade.\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "# 1. Entrada - Dicion√°rio simples\n",
    "input_data = {\"filme\": \"O Poderoso Chef√£o\"}\n",
    "\n",
    "# 2. Defina o prompt usando ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em filmes.\"),\n",
    "        (\"user\", \"Quem √© o diretor do filme : {filme}? Responda apenas com o nome.\")\n",
    "    ])\n",
    "# 3. Defina o parser de sa√≠da usando Pydantic\n",
    "llm_structured = llm.with_structured_output(DirectorMovie) # type: ignore\n",
    "\n",
    "# 4. Criando a chain co LCEL\n",
    "chain = prompt | llm_structured # type: ignore\n",
    "\n",
    "# 5. Execute a chain com os dados de entrada\n",
    "result = chain.invoke(input_data) # type: ignore\n",
    "\n",
    "# Processando sa√≠da\n",
    "print(f\"üìù Entrada: {input_data}\")\n",
    "print(f\"üîÑ Processamento: Prompt ‚Üí LLM ‚Üí Parser\")\n",
    "print(f\"‚ú® Resultado: {result.nome}\") #type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercicio_2():\n",
    "    \"\"\"\n",
    "    üìö OBJETIVO: Trabalhar com prompts mais complexos e m√∫ltiplas vari√°veis\n",
    "    \n",
    "    CONCEITO: Como o LangChain passa dados entre componentes\n",
    "    - O prompt recebe um dicion√°rio e formata as vari√°veis\n",
    "    - O LLM recebe o prompt formatado\n",
    "    - O parser limpa a resposta do LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ENTRADA - M√∫ltiplas vari√°veis\n",
    "    entrada = {\n",
    "        \"produto\": \"smartphone\",\n",
    "        \"marca\": \"Apple\",\n",
    "        \"preco\": \"R$ 3.500\",\n",
    "        \"publico\": \"jovens profissionais\"\n",
    "    }\n",
    "    \n",
    "    # 2. PROMPT - Template mais complexo\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em marketing digital.\"),\n",
    "        (\"human\", \"\"\"\n",
    "        Crie uma descri√ß√£o de produto para vendas online:\n",
    "        \n",
    "        Produto: {produto}\n",
    "        Marca: {marca}\n",
    "        Pre√ßo: {preco}\n",
    "        P√∫blico-alvo: {publico}\n",
    "        \n",
    "        A descri√ß√£o deve ser persuasiva e focada no p√∫blico-alvo.\n",
    "        \"\"\")\n",
    "    ])\n",
    "    \n",
    "    # 3. PARSER DE SA√çDA\n",
    "    parser = StrOutputParser()\n",
    "    \n",
    "    # 4. CHAIN\n",
    "    chain = prompt | llm | parser # type: ignore\n",
    "    \n",
    "    # 5. EXECU√á√ÉO\n",
    "    resultado = chain.invoke(entrada) # type: ignore\n",
    "    \n",
    "    print(f\"üìù Entrada: {entrada}\")\n",
    "    print(f\"‚ú® Descri√ß√£o do Produto:\\n{resultado}\")\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "# Executar exerc√≠cio 2\n",
    "resultado_2 = exercicio_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00fd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERC√çCIO 6: CHAIN COM SA√çDA ESTRUTURADA (PYDANTIC)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ EXERC√çCIO 6: CHAIN COM SA√çDA ESTRUTURADA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def exercicio_6():\n",
    "    \"\"\"\n",
    "    üìö OBJETIVO: Usar with_structured_output() para dados estruturados\n",
    "\n",
    "    VANTAGEM: Em vez de string livre, obtemos um objeto Python estruturado\n",
    "    - Valida√ß√£o autom√°tica dos dados\n",
    "    - Acesso direto aos campos\n",
    "    - Melhor para integra√ß√µes com outras partes do c√≥digo\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. MODELO PYDANTIC - Define a estrutura da sa√≠da\n",
    "    class AnaliseTexto(BaseModel):\n",
    "        \"\"\"Modelo para an√°lise estruturada de texto\"\"\"\n",
    "        sentimento: str = Field(description=\"Sentimento: positivo, negativo ou neutro\")\n",
    "        confianca: float = Field(description=\"N√≠vel de confian√ßa de 0 a 1\")\n",
    "        palavras_chave: List[str] = Field(description=\"Lista de palavras-chave importantes\")\n",
    "        resumo: str = Field(description=\"Resumo em uma frase\")\n",
    "\n",
    "    # 2. ENTRADA\n",
    "    entrada = {\n",
    "        \"texto\": \"\"\"\n",
    "        Estou absolutamente encantado com este produto! A qualidade superou todas as minhas \n",
    "        expectativas. O atendimento ao cliente foi excepcional, e a entrega foi mais r√°pida \n",
    "        do que prometido. Recomendo fortemente para qualquer pessoa que esteja considerando \n",
    "        esta compra. Definitivamente comprarei novamente!\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    # 3. PROMPT\n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"Voc√™ √© um especialista em an√°lise de sentimentos e texto.\"),\n",
    "        (\"human\", \"Analise o seguinte texto: {texto}\")\n",
    "    ])\n",
    "\n",
    "    # 4. LLM COM SA√çDA ESTRUTURADA - Substitui o StrOutputParser\n",
    "    llm_estruturado = llm.with_structured_output(AnaliseTexto) # type: ignore\n",
    "\n",
    "    # 5. CHAIN\n",
    "    chain = prompt | llm_estruturado # type: ignore\n",
    "\n",
    "    # 6. EXECU√á√ÉO\n",
    "    resultado = chain.invoke(entrada) # type: ignore\n",
    "\n",
    "    print(f\"üìù Texto analisado: {entrada['texto'][:100]}...\")\n",
    "    print(f\"üéØ Sentimento: {resultado.sentimento}\")\n",
    "    print(f\"üìä Confian√ßa: {resultado.confianca}\")\n",
    "    print(f\"üè∑Ô∏è  Palavras-chave: {resultado.palavras_chave}\")\n",
    "    print(f\"üìã Resumo: {resultado.resumo}\")\n",
    "\n",
    "    return resultado # type: ignore\n",
    "\n",
    "# Executar exerc√≠cio 3\n",
    "resultado_6 = exercicio_6() # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
