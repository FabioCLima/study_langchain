{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0216fe90",
   "metadata": {},
   "source": [
    "## Exercícios: LangChain - Conectores\n",
    "___\n",
    "\n",
    "* RunnableLambda\n",
    "* RunnableParallel\n",
    "* RunnablePassThrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a469ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e260cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "dobrar = RunnableLambda(lambda x: x * 2)\n",
    "print(dobrar.invoke(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb735ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336\n"
     ]
    }
   ],
   "source": [
    "print(dobrar.invoke(668))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c953255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "soma_lista = RunnableLambda(lambda lista: sum(lista))\n",
    "print(soma_lista.invoke([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a5322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLÁ, MUNDO!\n"
     ]
    }
   ],
   "source": [
    "to_upper = RunnableLambda(lambda input_str: input_str.upper())\n",
    "print(to_upper.invoke(\"Olá, mundo!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84dbe23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN\n"
     ]
    }
   ],
   "source": [
    "input_data = \"Langchain\"\n",
    "print(to_upper.invoke(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edebac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "count_char = RunnableLambda(lambda input_chars: len(input_chars))\n",
    "print(count_char.invoke(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e9eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(count_char.invoke(\"Olá, mundo!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbeeaab",
   "metadata": {},
   "source": [
    "`RunnableLambda` encadeado:\n",
    "\n",
    "**Encadeando `RunnableLambda` conseguimos criar pipelines de transformação.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f4eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as transformações\n",
    "to_upper = RunnableLambda(lambda input_str: input_str.upper())\n",
    "\n",
    "count_chars = RunnableLambda(\n",
    "    lambda input_chars: len(input_chars)\n",
    "    )\n",
    "\n",
    "# Montando pipeline (Encadeando as transformações)\n",
    "pipeline = to_upper | count_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21d8ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.invoke(\"Olá, mundo!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e12dd449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.invoke(\"Fabio Lima\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33defd",
   "metadata": {},
   "source": [
    "### RunnableParallel\n",
    "____\n",
    "\n",
    "**`RunnableParallel`**: Executa múltiplos `Runnables` em paralelo. Muito útil para montar dicionários que servirão de entrada para um prompt com vários placeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39793119",
   "metadata": {},
   "source": [
    "<h3>Enunciado:<h3>\n",
    "\n",
    "\n",
    "Crie um `RunnableParallel` que receba uma palavra e produza em paralelo:\n",
    "\n",
    "A palavra em maiúsculas\n",
    "\n",
    "A palavra em minúsculas\n",
    "\n",
    "O tamanho da palavra\n",
    "\n",
    "Explicação:\n",
    "\n",
    "O RunnableParallel executa diferentes transformações ao mesmo tempo sobre a mesma entrada, retornando um dicionário com os resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e39f2577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"upper\": \"FABIO LIMA\",\n",
      "    \"lower\": \"fabio lima\",\n",
      "    \"length\": 10\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "from langchain_core.runnables import RunnableSerializable\n",
    "\n",
    "pipeline: RunnableSerializable[str, Dict[str, Any]] = RunnableParallel({\n",
    "    \"upper\": to_upper,\n",
    "    \"lower\": RunnableLambda(lambda input_str: input_str.lower()),\n",
    "    \"length\": count_chars\n",
    "})#type: ignore\n",
    "\n",
    "result =pipeline.invoke(\"Fabio Lima\") #type: ignore\n",
    "print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588153ab",
   "metadata": {},
   "source": [
    "**`RunnablePassthrough`**: Um componente crucial para gerenciar dados.\n",
    "\n",
    "        * Sozinho, ele simplesmente passa a entrada adiante.\n",
    "        * Com **`.assign()`**, ele executa uma cadeia e adiciona\n",
    "        * seu resultado como uma nova chave no dicionário de entrada, **preservando os dados originais**. Este é o padrão-ouro para passar informações entre etapas de um workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184c6d4",
   "metadata": {},
   "source": [
    "`Enunciado`:\n",
    "\n",
    "Crie um pipeline que:\n",
    "1. Receba uma frase:\n",
    "2. Use `RunnablePassthrough` para passar a frase adiante sem alterar.\n",
    "3. Conte quantas palavras tem a frase \n",
    "\n",
    "Com **`RunnablePassthrough`** é útil quando queremos repassar a entrada intacta dentro de uma pipeline.\n",
    "Assim, pode se injetar a entrada original em diferentes pontos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f816e5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough #type: ignore\n",
    "#* 1. Receba uma frase:\n",
    "frase: str = \"A vida que se leva é a vida que se vive !\"\n",
    "\n",
    "#* 2. Use `RunnablePassthrough` para passar a frase adiante sem alterar.\n",
    "chain_1 = RunnablePassthrough() #type: ignore\n",
    "\n",
    "#* 3. Conte quantas palavras tem a frase de entrada: RunnableLambda\n",
    "count_words = RunnableLambda(lambda input_str: len(input_str.split())) #type: ignore\n",
    "\n",
    "#* 4. Pipeline:\n",
    "pipeline = chain_1 | count_words #type: ignore\n",
    "\n",
    "#* 5. Execute o pipeline:\n",
    "result = pipeline.invoke(frase) #type: ignore\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889f28d",
   "metadata": {},
   "source": [
    "#### `RunnablePassthrough().assign()`\n",
    "___\n",
    "\n",
    "Demonstração do RunnablePassthrough().assign()\n",
    "==============================================\n",
    "\n",
    "Este código complementa o exercício da célula 15 do notebook, demonstrando como\n",
    "o RunnablePassthrough().assign() executa uma chain e adiciona seu resultado\n",
    "como uma nova chave no dicionário de entrada, preservando os dados originais.\n",
    "\n",
    "Este é o padrão-ouro para passar informações entre etapas de um workflow.\n",
    "\n",
    "**`O input do pipeline de dados deve ser um dicionário de entrada.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e26417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d48413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase de entrada: A vida que se leva é a vida que se vive !\n"
     ]
    }
   ],
   "source": [
    "# Nossa frase base para os experimentos\n",
    "frase = \"A vida que se leva é a vida que se vive !\"\n",
    "print(\"Frase de entrada:\", frase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e2cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A entrada para o pipeline DEVE ser um dicionário.\n",
    "# A convenção é usar uma chave como \"input\" ou \"text\".\n",
    "input_dict = {\"input\": frase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "539a593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do pipeline básico:\n",
      "Frase original: A vida que se leva é a vida que se vive !\n",
      "Número de palavras: 12\n",
      "Frase em maiúsculas: A VIDA QUE SE LEVA É A VIDA QUE SE VIVE !\n",
      "Número de caracteres: 41\n"
     ]
    }
   ],
   "source": [
    "#* Cria pipeline que adiciona novos campos, mas mantém o original\n",
    "input = input_dict[\"input\"]\n",
    "pipeline_basico = RunnablePassthrough().assign(\n",
    "    num_palavras=RunnableLambda(lambda texto: len(input.split())),\n",
    "    frase_maiuscula=RunnableLambda(lambda texto: input.upper()),\n",
    "    num_caracteres=RunnableLambda(lambda texto: len(input))\n",
    ")\n",
    "\n",
    "resultado_basico = pipeline_basico.invoke(input_dict)\n",
    "\n",
    "print(\"Resultado do pipeline básico:\")\n",
    "print(\"Frase original:\", resultado_basico[\"input\"])\n",
    "print(\"Número de palavras:\", resultado_basico[\"num_palavras\"])\n",
    "print(\"Frase em maiúsculas:\", resultado_basico[\"frase_maiuscula\"])\n",
    "print(\"Número de caracteres:\", resultado_basico[\"num_caracteres\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abadbe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaves disponíveis no resultado: ['input', 'num_palavras', 'frase_maiuscula', 'num_caracteres']\n",
      "Estrutura completa do resultado (JSON):\n",
      "{\n",
      "  \"input\": \"A vida que se leva é a vida que se vive !\",\n",
      "  \"num_palavras\": 12,\n",
      "  \"frase_maiuscula\": \"A VIDA QUE SE LEVA É A VIDA QUE SE VIVE !\",\n",
      "  \"num_caracteres\": 41\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Chaves disponíveis no resultado:\", list(resultado_basico.keys()))\n",
    "print(\"Estrutura completa do resultado (JSON):\")\n",
    "print(json.dumps(resultado_basico, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cadb173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrutura completa do resultado (JSON): \n",
      "Resultado da pipeline básica =\n",
      "\n",
      "{\n",
      "    \"input\": \"A vida que se leva é a vida que se vive !\",\n",
      "    \"num_palavras\": 12,\n",
      "    \"frase_maiuscula\": \"A VIDA QUE SE LEVA É A VIDA QUE SE VIVE !\",\n",
      "    \"num_caracteres\": 41\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Estrutura completa do resultado (JSON): \\nResultado da pipeline básica =\\n\")\n",
    "print(json.dumps(resultado_basico, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf54e36",
   "metadata": {},
   "source": [
    "Para o `pipeline avançado` utilizamos as operações do `pipeline básico`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f916754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análise detalhada:\n",
      "  palavras_por_caractere: 0.293\n",
      "  tem_exclamacao: True\n",
      "  palavras_unicas: 8\n",
      "  palavra_mais_longa: vida\n"
     ]
    }
   ],
   "source": [
    "pipeline_avancado = pipeline_basico.assign(\n",
    "    analise=RunnableLambda(lambda dados: {\n",
    "        \"palavras_por_caractere\": round(dados[\"num_palavras\"] / dados[\"num_caracteres\"], 3),\n",
    "        \"tem_exclamacao\": \"!\" in dados[\"input\"],\n",
    "        \"palavras_unicas\": len(set(dados[\"input\"].lower().split())),\n",
    "        \"palavra_mais_longa\": max(dados[\"input\"].split(), key=len),\n",
    "    })\n",
    ")\n",
    "\n",
    "resultado_avancado = pipeline_avancado.invoke(input_dict)\n",
    "\n",
    "print(\"Análise detalhada:\")\n",
    "for chave, valor in resultado_avancado[\"analise\"].items():\n",
    "    print(f\"  {chave}: {valor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac465a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cascata = (\n",
    "    RunnablePassthrough()\n",
    "    .assign(\n",
    "        estatisticas_basicas=RunnableLambda(lambda dados: {\n",
    "            \"comprimento\": len(dados[\"input\"]),\n",
    "            \"palavras\": len(dados[\"input\"].split()),\n",
    "            \"caracteres_sem_espaco\": len(dados[\"input\"].replace(\" \", \"\")),\n",
    "        })\n",
    "    )\n",
    "    .assign(\n",
    "        analise_semantica=RunnableLambda(lambda dados: {\n",
    "            \"tem_pontuacao\": any(c in dados[\"input\"] for c in \"!?.,;:\"),\n",
    "            \"densidade_texto\": round(\n",
    "                dados[\"estatisticas_basicas\"][\"caracteres_sem_espaco\"]\n",
    "                / dados[\"estatisticas_basicas\"][\"comprimento\"], 3\n",
    "            )\n",
    "        })\n",
    "    )\n",
    "    .assign(\n",
    "        resumo=RunnableLambda(lambda dados: {\n",
    "            \"texto_curto\": dados[\"estatisticas_basicas\"][\"comprimento\"] < 50,\n",
    "            \"denso\": dados[\"analise_semantica\"][\"densidade_texto\"] > 0.7,\n",
    "            \"complexidade\": \"alta\" if dados[\"estatisticas_basicas\"][\"palavras\"] > 10 else \"baixa\"\n",
    "        })\n",
    "    )\n",
    ")\n",
    "\n",
    "resultado_cascata = pipeline_cascata.invoke(input_dict)\n",
    "\n",
    "print(\"Resultado do pipeline em cascata:\")\n",
    "print(\"  Estatísticas básicas:\", resultado_cascata[\"estatisticas_basicas\"])\n",
    "print(\"  Análise semântica:\", resultado_cascata[\"analise_semantica\"])\n",
    "print(\"  Resumo:\", resultado_cascata[\"resumo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01b7e1",
   "metadata": {},
   "source": [
    "### Caso de uso real: Classificação de textos:\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_exemplo = [\n",
    "    \"Python é uma linguagem de programação incrível!\",\n",
    "    \"A inteligência artificial está revolucionando o mundo.\",\n",
    "    \"Olá, como você está hoje?\",\n",
    "    \"Este é um texto muito longo que contém muitas palavras e informações detalhadas.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d59c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_classificacao = (\n",
    "    RunnablePassthrough()\n",
    "    .assign(\n",
    "        caracteristicas=RunnableLambda(lambda texto: {\n",
    "            \"comprimento\": len(texto),\n",
    "            \"palavras\": len(texto.split()),\n",
    "            \"tem_exclamacao\": \"!\" in texto,\n",
    "            \"tem_interrogacao\": \"?\" in texto,\n",
    "        })\n",
    "    )\n",
    "    .assign(\n",
    "        classificacao=RunnableLambda(lambda dados: {\n",
    "            \"tipo\": (\n",
    "                \"exclamativo\" if dados[\"caracteristicas\"][\"tem_exclamacao\"]\n",
    "                else \"interrogativo\" if dados[\"caracteristicas\"][\"tem_interrogacao\"]\n",
    "                else \"declarativo\"\n",
    "            ),\n",
    "            \"complexidade\": (\n",
    "                \"alta\" if dados[\"caracteristicas\"][\"palavras\"] > 15\n",
    "                else \"média\" if dados[\"caracteristicas\"][\"palavras\"] > 8\n",
    "                else \"baixa\"\n",
    "            )\n",
    "        })\n",
    "    )\n",
    ")\n",
    "\n",
    "for i, texto in enumerate(textos_exemplo, 1):\n",
    "    resultado = pipeline_classificacao.invoke(texto)\n",
    "    print(f\"\\nTexto {i}: '{texto}'\")\n",
    "    print(\"  Características:\", resultado[\"caracteristicas\"])\n",
    "    print(\"  Classificação:\", resultado[\"classificacao\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19830cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMO: Vantagens do RunnablePassthrough().assign()\")\n",
    "print(\"=\" * 60)\n",
    "print(\"✅ Mantém os dados originais intactos (input)\")\n",
    "print(\"✅ Permite adicionar novos resultados incrementalmente\")\n",
    "print(\"✅ Facilita a criação de pipelines em múltiplas etapas\")\n",
    "print(\"✅ Ajuda no debugging e manutenção\")\n",
    "print(\"✅ Ideal para casos reais como classificação e análise de texto\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
