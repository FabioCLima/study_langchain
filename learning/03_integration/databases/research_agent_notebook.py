# Agente Pesquisador Inteligente usando LangGraph
# Exemplo DidÃ¡tico com Tool Use e Reflection Patterns

"""
Este notebook demonstra a implementaÃ§Ã£o de um agente de IA que combina:
1. Tool Use Pattern: Para buscar informaÃ§Ãµes e fazer cÃ¡lculos
2. Reflection Pattern: Para avaliar e melhorar suas respostas

O agente pode pesquisar informaÃ§Ãµes, analisar dados e refinar suas conclusÃµes.
"""

# =============================================================================
# SEÃ‡ÃƒO 1: INSTALAÃ‡ÃƒO E CONFIGURAÃ‡ÃƒO
# =============================================================================

# Execute no terminal ou primeira cÃ©lula:
# !pip install langchain-openai langgraph langchain-core python-dotenv requests

import os
import json
import requests
from typing import List, Dict, Any, Optional, Literal, TypedDict
from datetime import datetime
import logging

# LangChain e LangGraph imports
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ConfiguraÃ§Ã£o da API Key (coloque sua chave da OpenAI)
# Recomenda-se usar um arquivo .env para isso
os.environ["OPENAI_API_KEY"] = "sua-chave-openai-aqui"

print("âœ… DependÃªncias carregadas com sucesso!")

# =============================================================================
# SEÃ‡ÃƒO 2: DEFINIÃ‡ÃƒO DO ESTADO DO AGENTE
# =============================================================================

class ResearchAgentState(TypedDict):
    """
    Estado do agente de pesquisa que mantÃ©m todas as informaÃ§Ãµes necessÃ¡rias
    durante o fluxo de execuÃ§Ã£o.
    
    Attributes:
        messages: Lista de mensagens na conversa
        research_query: Consulta de pesquisa atual
        search_results: Resultados da busca
        draft_response: Rascunho da resposta
        reflection: AnÃ¡lise crÃ­tica da resposta
        final_response: Resposta final refinada
        iteration_count: NÃºmero de iteraÃ§Ãµes de refinamento
        max_iterations: MÃ¡ximo de iteraÃ§Ãµes permitidas
        tools_used: Lista de ferramentas utilizadas
        confidence_score: PontuaÃ§Ã£o de confianÃ§a na resposta (0-10)
    """
    messages: List[BaseMessage]
    research_query: str
    search_results: List[Dict[str, Any]]
    draft_response: str
    reflection: str
    final_response: str
    iteration_count: int
    max_iterations: int
    tools_used: List[str]
    confidence_score: float

print("âœ… Estado do agente definido!")

# =============================================================================
# SEÃ‡ÃƒO 3: DEFINIÃ‡ÃƒO DAS FERRAMENTAS (TOOL USE PATTERN)
# =============================================================================

@tool
def web_search_simulator(query: str) -> str:
    """
    Simula uma busca na web retornando resultados fictÃ­cios mas realistas.
    
    Em um ambiente real, vocÃª integraria com APIs como Google Search, Bing, etc.
    
    Args:
        query: Termo de busca
        
    Returns:
        Resultados da busca em formato JSON string
    """
    # SimulaÃ§Ã£o de resultados baseados na query
    mock_results = {
        "inteligÃªncia artificial": [
            {
                "title": "IA na EducaÃ§Ã£o: Transformando o Aprendizado",
                "snippet": "A inteligÃªncia artificial estÃ¡ revolucionando a educaÃ§Ã£o com personalizaÃ§Ã£o de aprendizado e tutoria inteligente.",
                "source": "TechEducation.com"
            },
            {
                "title": "BenefÃ­cios e Desafios da IA",
                "snippet": "IA oferece automaÃ§Ã£o e insights, mas levanta questÃµes Ã©ticas e de emprego.",
                "source": "AIResearch.org"
            }
        ],
        "mudanÃ§as climÃ¡ticas": [
            {
                "title": "Impactos Globais das MudanÃ§as ClimÃ¡ticas",
                "snippet": "Temperatura global aumentou 1.1Â°C desde 1880, afetando ecossistemas mundialmente.",
                "source": "ClimateScience.gov"
            },
            {
                "title": "SoluÃ§Ãµes para o Clima",
                "snippet": "Energias renovÃ¡veis e eficiÃªncia energÃ©tica sÃ£o chaves para mitigaÃ§Ã£o climÃ¡tica.",
                "source": "GreenTech.net"
            }
        ],
        "default": [
            {
                "title": f"InformaÃ§Ãµes sobre {query}",
                "snippet": f"Dados relevantes encontrados sobre {query} incluindo aspectos tÃ©cnicos e prÃ¡ticos.",
                "source": "GeneralKnowledge.com"
            }
        ]
    }
    
    # Seleciona resultados baseados na query
    for key in mock_results:
        if key in query.lower():
            results = mock_results[key]
            break
    else:
        results = mock_results["default"]
    
    logger.info(f"ğŸ” Busca realizada para: {query}")
    return json.dumps(results, ensure_ascii=False, indent=2)

@tool
def calculate_metrics(numbers: List[float], operation: str) -> str:
    """
    Realiza cÃ¡lculos estatÃ­sticos bÃ¡sicos em uma lista de nÃºmeros.
    
    Args:
        numbers: Lista de nÃºmeros para calcular
        operation: Tipo de operaÃ§Ã£o ('mean', 'sum', 'max', 'min', 'median')
        
    Returns:
        Resultado do cÃ¡lculo
    """
    if not numbers:
        return "Erro: Lista de nÃºmeros vazia"
    
    try:
        if operation == "mean":
            result = sum(numbers) / len(numbers)
        elif operation == "sum":
            result = sum(numbers)
        elif operation == "max":
            result = max(numbers)
        elif operation == "min":
            result = min(numbers)
        elif operation == "median":
            sorted_nums = sorted(numbers)
            n = len(sorted_nums)
            if n % 2 == 0:
                result = (sorted_nums[n//2 - 1] + sorted_nums[n//2]) / 2
            else:
                result = sorted_nums[n//2]
        else:
            return f"Erro: OperaÃ§Ã£o '{operation}' nÃ£o suportada"
        
        logger.info(f"ğŸ§® Calculado {operation} de {numbers}: {result}")
        return f"Resultado da operaÃ§Ã£o '{operation}': {result}"
    
    except Exception as e:
        return f"Erro no cÃ¡lculo: {str(e)}"

@tool
def fact_checker(claim: str) -> str:
    """
    Simula verificaÃ§Ã£o de fatos para uma afirmaÃ§Ã£o.
    
    Args:
        claim: AfirmaÃ§Ã£o a ser verificada
        
    Returns:
        Status de verificaÃ§Ã£o da afirmaÃ§Ã£o
    """
    # SimulaÃ§Ã£o simples de fact-checking
    fact_database = {
        "terra Ã© redonda": "VERDADEIRO - Confirmado por evidÃªncias cientÃ­ficas",
        "temperatura global": "VERDADEIRO - Dados confirmados por organizaÃ§Ãµes climÃ¡ticas",
        "ia substitui humanos": "PARCIALMENTE VERDADEIRO - IA automatiza tarefas especÃ­ficas, nÃ£o substitui completamente",
        "vacinas": "VERDADEIRO - EficÃ¡cia comprovada cientificamente"
    }
    
    claim_lower = claim.lower()
    for key, value in fact_database.items():
        if key in claim_lower:
            logger.info(f"âœ… VerificaÃ§Ã£o realizada para: {claim}")
            return f"VerificaÃ§Ã£o: {value}"
    
    return "NECESSITA VERIFICAÃ‡ÃƒO - NÃ£o hÃ¡ dados suficientes na base de conhecimento"

# Lista de todas as ferramentas disponÃ­veis
AVAILABLE_TOOLS = [web_search_simulator, calculate_metrics, fact_checker]

print("âœ… Ferramentas definidas!")

# =============================================================================
# SEÃ‡ÃƒO 4: CONFIGURAÃ‡ÃƒO DO MODELO E FERRAMENTAS
# =============================================================================

def setup_llm_with_tools() -> ChatOpenAI:
    """
    Configura o modelo de linguagem com as ferramentas disponÃ­veis.
    
    Returns:
        Modelo ChatOpenAI configurado com ferramentas
    """
    llm = ChatOpenAI(
        model="gpt-4",
        temperature=0.1,  # Baixa temperatura para maior consistÃªncia
        timeout=60
    )
    
    # Vincula as ferramentas ao modelo
    llm_with_tools = llm.bind_tools(AVAILABLE_TOOLS)
    
    logger.info("ğŸ¤– Modelo configurado com ferramentas")
    return llm_with_tools

# Instancia o modelo
llm_with_tools = setup_llm_with_tools()

print("âœ… Modelo configurado!")

# =============================================================================
# SEÃ‡ÃƒO 5: FUNÃ‡Ã•ES DOS NÃ“S DO GRAFO
# =============================================================================

def query_analyzer_node(state: ResearchAgentState) -> Dict[str, Any]:
    """
    Analisa a consulta do usuÃ¡rio e determina a estratÃ©gia de pesquisa.
    
    Args:
        state: Estado atual do agente
        
    Returns:
        Estado atualizado com anÃ¡lise da consulta
    """
    user_message = state["messages"][-1].content if state["messages"] else ""
    
    analysis_prompt = f"""
    Analise a seguinte consulta do usuÃ¡rio e determine:
    1. Qual Ã© a intenÃ§Ã£o principal da pergunta?
    2. Que tipo de informaÃ§Ãµes precisamos buscar?
    3. Quais ferramentas seriam mais Ãºteis?
    
    Consulta: {user_message}
    
    ForneÃ§a uma anÃ¡lise estruturada.
    """
    
    system_message = SystemMessage(content="VocÃª Ã© um analisador de consultas especializado.")
    analysis_message = HumanMessage(content=analysis_prompt)
    
    response = llm_with_tools.invoke([system_message, analysis_message])
    
    # Extrai a consulta principal para pesquisa
    research_query = user_message  # Simplificado para este exemplo
    
    logger.info(f"ğŸ” Consulta analisada: {research_query}")
    
    return {
        **state,
        "research_query": research_query,
        "tools_used": ["query_analysis"]
    }

def research_node(state: ResearchAgentState) -> Dict[str, Any]:
    """
    Executa a pesquisa usando as ferramentas disponÃ­veis (Tool Use Pattern).
    
    Args:
        state: Estado atual do agente
        
    Returns:
        Estado atualizado com resultados da pesquisa
    """
    query = state["research_query"]
    
    # Prompt para o agente decidir quais ferramentas usar
    research_prompt = f"""
    VocÃª precisa pesquisar informaÃ§Ãµes sobre: {query}
    
    Use as ferramentas disponÃ­veis para coletar dados relevantes:
    - web_search_simulator: para buscar informaÃ§Ãµes gerais
    - calculate_metrics: para cÃ¡lculos se necessÃ¡rio
    - fact_checker: para verificar informaÃ§Ãµes
    
    Comece com uma busca web sobre o tÃ³pico.
    """
    
    system_message = SystemMessage(content="VocÃª Ã© um pesquisador que usa ferramentas para coletar informaÃ§Ãµes.")
    research_message = HumanMessage(content=research_prompt)
    
    response = llm_with_tools.invoke([system_message, research_message])
    
    # Se hÃ¡ tool calls, executa as ferramentas
    if hasattr(response, 'tool_calls') and response.tool_calls:
        tool_node = ToolNode(AVAILABLE_TOOLS)
        tool_results = tool_node.invoke({"messages": [response]})
        
        # Processa os resultados das ferramentas
        search_results = []
        for message in tool_results["messages"]:
            if hasattr(message, 'content'):
                try:
                    # Tenta fazer parse se for JSON
                    result = json.loads(message.content)
                    if isinstance(result, list):
                        search_results.extend(result)
                    else:
                        search_results.append(result)
                except json.JSONDecodeError:
                    # Se nÃ£o for JSON, adiciona como texto
                    search_results.append({"content": message.content})
    else:
        search_results = [{"content": "Nenhuma ferramenta foi utilizada"}]
    
    logger.info(f"ğŸ“Š Pesquisa concluÃ­da com {len(search_results)} resultados")
    
    return {
        **state,
        "search_results": search_results,
        "tools_used": state["tools_used"] + ["web_search"]
    }

def draft_generator_node(state: ResearchAgentState) -> Dict[str, Any]:
    """
    Gera um rascunho de resposta baseado nos resultados da pesquisa.
    
    Args:
        state: Estado atual do agente
        
    Returns:
        Estado atualizado com rascunho da resposta
    """
    query = state["research_query"]
    search_results = state["search_results"]
    
    # Formata os resultados da pesquisa
    formatted_results = "\n".join([
        f"- {result.get('title', 'Info')}: {result.get('snippet', result.get('content', 'N/A'))}"
        for result in search_results
    ])
    
    draft_prompt = f"""
    Com base na pesquisa realizada, elabore uma resposta completa e informativa para a pergunta: {query}
    
    Dados coletados:
    {formatted_results}
    
    Sua resposta deve ser:
    - Precisa e baseada nos dados coletados
    - Bem estruturada e fÃ¡cil de entender
    - Incluir fontes quando relevante
    - Abordar diferentes aspectos do tÃ³pico
    """
    
    system_message = SystemMessage(content="VocÃª Ã© um especialista em sintetizar informaÃ§Ãµes de pesquisa.")
    draft_message = HumanMessage(content=draft_prompt)
    
    draft_response = llm_with_tools.invoke([system_message, draft_message])
    
    logger.info("ğŸ“ Rascunho da resposta gerado")
    
    return {
        **state,
        "draft_response": draft_response.content,
        "iteration_count": 1
    }

def reflection_node(state: ResearchAgentState) -> Dict[str, Any]:
    """
    Aplica o Reflection Pattern para avaliar e melhorar a resposta.
    
    Args:
        state: Estado atual do agente
        
    Returns:
        Estado atualizado com reflexÃ£o sobre a resposta
    """
    draft = state["draft_response"]
    query = state["research_query"]
    
    reflection_prompt = f"""
    Analise criticamente a seguinte resposta para a pergunta: "{query}"
    
    RESPOSTA A SER ANALISADA:
    {draft}
    
    Avalie os seguintes aspectos e dÃª uma nota de 0 a 10:
    1. PRECISÃƒO: As informaÃ§Ãµes estÃ£o corretas e bem fundamentadas?
    2. COMPLETUDE: A resposta aborda todos os aspectos importantes?
    3. CLAREZA: A explicaÃ§Ã£o Ã© fÃ¡cil de entender?
    4. ESTRUTURA: A organizaÃ§Ã£o do texto Ã© lÃ³gica?
    5. RELEVÃ‚NCIA: O conteÃºdo responde diretamente Ã  pergunta?
    
    ForneÃ§a:
    - Uma nota geral de 0 a 10
    - Pontos fortes identificados
    - Ãreas especÃ­ficas que precisam de melhoria
    - SugestÃµes concretas de como melhorar
    """
    
    system_message = SystemMessage(content="VocÃª Ã© um crÃ­tico especializado em avaliar qualidade de respostas.")
    reflection_message = HumanMessage(content=reflection_prompt)
    
    reflection_response = llm_with_tools.invoke([system_message, reflection_message])
    
    # Extrai a pontuaÃ§Ã£o de confianÃ§a (simplificado)
    confidence_score = 7.0  # Por padrÃ£o, assumimos uma confianÃ§a mÃ©dia
    content = reflection_response.content.lower()
    
    # Busca por padrÃµes de pontuaÃ§Ã£o no texto
    import re
    scores = re.findall(r'(?:nota|score|pontuaÃ§Ã£o)[:\s]*([0-9]+(?:\.[0-9]+)?)', content)
    if scores:
        try:
            confidence_score = float(scores[0])
        except ValueError:
            pass
    
    logger.info(f"ğŸ¤” ReflexÃ£o realizada - ConfianÃ§a: {confidence_score}")
    
    return {
        **state,
        "reflection": reflection_response.content,
        "confidence_score": confidence_score
    }

def revision_node(state: ResearchAgentState) -> Dict[str, Any]:
    """
    Revisa e melhora a resposta com base na reflexÃ£o.
    
    Args:
        state: Estado atual do agente
        
    Returns:
        Estado atualizado com resposta revisada
    """
    draft = state["draft_response"]
    reflection = state["reflection"]
    query = state["research_query"]
    
    revision_prompt = f"""
    Melhore a seguinte resposta incorporando as crÃ­ticas e sugestÃµes fornecidas:
    
    PERGUNTA ORIGINAL: {query}
    
    RESPOSTA ATUAL:
    {draft}
    
    ANÃLISE CRÃTICA:
    {reflection}
    
    Reescreva a resposta implementando as melhorias sugeridas. Mantenha o que estÃ¡ bom e melhore o que foi criticado.
    """
    
    system_message = SystemMessage(content="VocÃª Ã© um editor especializado em melhorar textos baseado em feedback.")
    revision_message = HumanMessage(content=revision_prompt)
    
    revised_response = llm_with_tools.invoke([system_message, revision_message])
    
    logger.info("âœï¸ Resposta revisada")
    
    return {
        **state,
        "draft_response": revised_response.content,
        "iteration_count": state["iteration_count"] + 1
    }

def finalization_node(state: ResearchAgentState) -> Dict[str, Any]:
    """
    Finaliza a resposta e prepara o resultado final.
    
    Args:
        state: Estado atual do agente
        
    Returns:
        Estado final com resposta completa
    """
    final_response = state["draft_response"]
    tools_used = state["tools_used"]
    confidence = state["confidence_score"]
    iterations = state["iteration_count"]
    
    # Adiciona metadados Ã  resposta final
    metadata = f"""
    
    ---
    ğŸ“Š Metadados da Pesquisa:
    â€¢ Ferramentas utilizadas: {', '.join(tools_used)}
    â€¢ IteraÃ§Ãµes de refinamento: {iterations}
    â€¢ ConfianÃ§a na resposta: {confidence}/10
    â€¢ Processado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    """
    
    final_with_metadata = final_response + metadata
    
    logger.info("ğŸ¯ Resposta finalizada")
    
    return {
        **state,
        "final_response": final_with_metadata
    }

print("âœ… FunÃ§Ãµes dos nÃ³s definidas!")

# =============================================================================
# SEÃ‡ÃƒO 6: FUNÃ‡Ã•ES DE DECISÃƒO DO FLUXO
# =============================================================================

def should_continue_research(state: ResearchAgentState) -> Literal["draft", "research"]:
    """
    Decide se deve continuar pesquisando ou gerar rascunho.
    
    Args:
        state: Estado atual do agente
        
    Returns:
        PrÃ³ximo nÃ³ do fluxo
    """
    search_results = state.get("search_results", [])
    
    # Se temos resultados, prosseguir para o rascunho
    if search_results:
        return "draft"
    else:
        return "research"

def should_revise(state: ResearchAgentState) -> Literal["revision", "finalize"]:
    """
    Decide se a resposta precisa ser revisada ou pode ser finalizada.
    
    Args:
        state: Estado atual do agente
        
    Returns:
        PrÃ³ximo nÃ³ do fluxo
    """
    confidence = state.get("confidence_score", 0)
    iterations = state.get("iteration_count", 0)
    max_iterations = state.get("max_iterations", 2)
    
    # Se confianÃ§a Ã© baixa e nÃ£o excedeu max iteraÃ§Ãµes, revisar
    if confidence < 7.0 and iterations < max_iterations:
        return "revision"
    else:
        return "finalize"

print("âœ… FunÃ§Ãµes de decisÃ£o definidas!")

# =============================================================================
# SEÃ‡ÃƒO 7: CONSTRUÃ‡ÃƒO DO GRAFO DO AGENTE
# =============================================================================

def create_research_agent() -> StateGraph:
    """
    Cria e configura o grafo do agente de pesquisa.
    
    Returns:
        Grafo compilado do agente
    """
    # Cria o grafo
    workflow = StateGraph(ResearchAgentState)
    
    # Adiciona todos os nÃ³s
    workflow.add_node("analyze_query", query_analyzer_node)
    workflow.add_node("research", research_node)
    workflow.add_node("draft", draft_generator_node)
    workflow.add_node("reflect", reflection_node)
    workflow.add_node("revision", revision_node)
    workflow.add_node("finalize", finalization_node)
    
    # Define o ponto de entrada
    workflow.set_entry_point("analyze_query")
    
    # Define as conexÃµes entre os nÃ³s
    workflow.add_edge("analyze_query", "research")
    workflow.add_conditional_edges("research", should_continue_research)
    workflow.add_edge("draft", "reflect")
    workflow.add_conditional_edges("reflect", should_revise)
    workflow.add_edge("revision", "reflect")  # Volta para reflexÃ£o apÃ³s revisÃ£o
    workflow.add_edge("finalize", END)
    
    # Compila o grafo
    agent = workflow.compile()
    
    logger.info("ğŸ—ï¸ Agente de pesquisa construÃ­do com sucesso!")
    return agent

# Cria o agente
research_agent = create_research_agent()

print("âœ… Agente de pesquisa criado!")

# =============================================================================
# SEÃ‡ÃƒO 8: FUNÃ‡ÃƒO DE EXECUÃ‡ÃƒO E TESTE
# =============================================================================

def run_research_agent(question: str, max_iterations: int = 2) -> Dict[str, Any]:
    """
    Executa o agente de pesquisa com uma pergunta.
    
    Args:
        question: Pergunta para pesquisar
        max_iterations: MÃ¡ximo de iteraÃ§Ãµes de refinamento
        
    Returns:
        Resultado completo da execuÃ§Ã£o
    """
    print(f"\nğŸš€ Iniciando pesquisa: {question}")
    print("=" * 60)
    
    # Estado inicial
    initial_state = ResearchAgentState(
        messages=[HumanMessage(content=question)],
        research_query="",
        search_results=[],
        draft_response="",
        reflection="",
        final_response="",
        iteration_count=0,
        max_iterations=max_iterations,
        tools_used=[],
        confidence_score=0.0
    )
    
    # Executa o agente
    try:
        result = research_agent.invoke(initial_state)
        
        print("\nâœ… PESQUISA CONCLUÃDA!")
        print("=" * 60)
        print(result["final_response"])
        
        return result
        
    except Exception as e:
        print(f"\nâŒ Erro durante a execuÃ§Ã£o: {str(e)}")
        return {"error": str(e)}

print("âœ… Sistema completo configurado!")

# =============================================================================
# SEÃ‡ÃƒO 9: EXEMPLOS DE TESTE
# =============================================================================

# Exemplo 1: Teste bÃ¡sico
print("\n" + "="*80)
print("ğŸ§ª EXEMPLO 1: Teste sobre InteligÃªncia Artificial")
print("="*80)

exemplo_1 = run_research_agent(
    "Quais sÃ£o os principais benefÃ­cios da inteligÃªncia artificial na educaÃ§Ã£o?",
    max_iterations=2
)

# Exemplo 2: Teste sobre tema cientÃ­fico
print("\n" + "="*80)
print("ğŸ§ª EXEMPLO 2: Teste sobre MudanÃ§as ClimÃ¡ticas")
print("="*80)

exemplo_2 = run_research_agent(
    "Como as mudanÃ§as climÃ¡ticas estÃ£o afetando os oceanos?",
    max_iterations=1
)

# =============================================================================
# SEÃ‡ÃƒO 10: ANÃLISE DOS RESULTADOS E PRÃ“XIMOS PASSOS
# =============================================================================

print("\n" + "="*80)
print("ğŸ“Š ANÃLISE DOS RESULTADOS")
print("="*80)

def analyze_results(result: Dict[str, Any], example_name: str) -> None:
    """
    Analisa e apresenta os resultados de uma execuÃ§Ã£o do agente.
    
    Args:
        result: Resultado da execuÃ§Ã£o
        example_name: Nome do exemplo para identificaÃ§Ã£o
    """
    if "error" in result:
        print(f"âŒ {example_name}: Erro encontrado - {result['error']}")
        return
    
    print(f"\nğŸ“‹ {example_name}:")
    print(f"   â€¢ Ferramentas usadas: {result.get('tools_used', [])}")
    print(f"   â€¢ IteraÃ§Ãµes: {result.get('iteration_count', 0)}")
    print(f"   â€¢ ConfianÃ§a: {result.get('confidence_score', 0)}/10")
    print(f"   â€¢ Resultados de pesquisa: {len(result.get('search_results', []))}")

analyze_results(exemplo_1, "Exemplo IA na EducaÃ§Ã£o")
analyze_results(exemplo_2, "Exemplo MudanÃ§as ClimÃ¡ticas")

print("\n" + "="*80)
print("ğŸ¯ PRÃ“XIMOS PASSOS E MELHORIAS")
print("="*80)

print("""
Este agente demonstra os conceitos fundamentais, mas pode ser melhorado:

ğŸ”§ MELHORIAS TÃ‰CNICAS:
   â€¢ Integrar APIs reais (Google Search, Wikipedia, etc.)
   â€¢ Adicionar mais ferramentas especializadas
   â€¢ Implementar cache de resultados
   â€¢ Melhorar anÃ¡lise de confianÃ§a
   â€¢ Adicionar tratamento de erros mais robusto

ğŸ¨ MELHORIAS DE UX:
   â€¢ Interface grÃ¡fica interativa
   â€¢ Streaming de respostas em tempo real
   â€¢ VisualizaÃ§Ã£o do grafo de execuÃ§Ã£o
   â€¢ HistÃ³rico de conversas
   â€¢ ExportaÃ§Ã£o de resultados

ğŸ“Š MELHORIAS DE PERFORMANCE:
   â€¢ ExecuÃ§Ã£o paralela de ferramentas
   â€¢ OtimizaÃ§Ã£o de prompts
   â€¢ Modelo de linguagem fine-tuned
   â€¢ MÃ©tricas detalhadas de performance

ğŸ”’ MELHORIAS DE SEGURANÃ‡A:
   â€¢ ValidaÃ§Ã£o de entrada
   â€¢ SanitizaÃ§Ã£o de dados
   â€¢ Rate limiting
   â€¢ Auditoria de execuÃ§Ãµes
""")

print("\nâœ¨ Agente de Pesquisa Inteligente executado com sucesso!")
print("ğŸ“š Este exemplo demonstra como combinar Tool Use e Reflection patterns")
print("ğŸš€ Pronto para ser estendido com suas prÃ³prias ferramentas e casos de uso!")
