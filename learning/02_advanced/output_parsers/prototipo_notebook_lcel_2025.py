# File: src/prototipo_notebook_lcel_2025.py
# Este script √© projetado para ser executado c√©lula por c√©lula em um Jupyter Notebook.

# --- [C√âLULA 1] ---
# Imports e Configura√ß√£o do Ambiente
# Adicionamos asyncio para opera√ß√µes ass√≠ncronas e IPython para display no notebook.
import asyncio
import os
from operator import itemgetter

from dotenv import find_dotenv, load_dotenv
from IPython.display import Markdown, clear_output, display
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable, RunnablePassthrough
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

print("‚úÖ C√©lula 1: Imports e configura√ß√£o conclu√≠dos.")

# --- [C√âLULA 2] ---
# Carregamento da API e Inst√¢ncia do Modelo
# A estrutura √© mantida, pois √© uma boa pr√°tica.
API_KEY_ERROR_MSG = "OPENAI_API_KEY n√£o encontrada no arquivo .env."
MODEL_NAME = "gpt-4-turbo"
MODEL_TEMPERATURE = 0.5


def carregar_api_key() -> None:
    """Carrega a chave da API OpenAI do ambiente e verifica sua exist√™ncia."""
    load_dotenv(find_dotenv())
    if not os.getenv("OPENAI_API_KEY"):
        raise ValueError(API_KEY_ERROR_MSG)
    # Dica para 2025: Ative o LangSmith para observabilidade!
    # os.environ["LANGCHAIN_TRACING_V2"] = "true"
    # os.environ["LANGCHAIN_API_KEY"] = "sua_chave_langsmith"


carregar_api_key()
model = ChatOpenAI(model=MODEL_NAME, temperature=MODEL_TEMPERATURE)

print("‚úÖ C√©lula 2: Modelo LLM instanciado.")


# --- [C√âLULA 3] ---
# Defini√ß√µes dos Modelos de Dados (Pydantic)
# Nenhuma mudan√ßa aqui, Pydantic continua sendo o padr√£o ouro para estrutura√ß√£o de dados.
class Destino(BaseModel):
    cidade: str = Field(description="A cidade recomendada para visitar.")
    motivo: str = Field(description="Motivo pelo qual √© interessante visitar essa cidade.")


class Restaurantes(BaseModel):
    sugestoes: list[str] = Field(description="Uma lista com nomes de 3 a 5 restaurantes recomendados.")


# Adicionamos uma nova chain para a previs√£o do tempo, como sugerido no plano de estudos.
class PrevisaoTempo(BaseModel):
    previsao: str = Field(description="Uma breve previs√£o do tempo para a cidade, incluindo temperatura m√©dia e condi√ß√µes.")


print("‚úÖ C√©lula 3: Modelos Pydantic definidos.")

# --- [C√âLULA 4] ---
# Fun√ß√µes para Criar as Cadeias (Chains) Modulares
# A modularidade √© excelente e deve ser mantida.
# Adicionamos a chain de previs√£o do tempo e a de resumo.


def criar_chain_sugestao_destino() -> Runnable:
    prompt_destino = ChatPromptTemplate.from_template(
        "Voc√™ √© um especialista em viagens. Sugira uma cidade para algu√©m com interesse em {interesse}. "
        "Forne√ßa a cidade e um motivo."
    )
    # Usando .with_structured_output, a forma mais moderna e robusta.
    return prompt_destino | model.with_structured_output(Destino)


def criar_chain_sugestao_restaurantes() -> Runnable:
    prompt_restaurantes = ChatPromptTemplate.from_template(
        "Com base na cidade {cidade}, sugira 3 restaurantes locais."
    )
    return prompt_restaurantes | model.with_structured_output(Restaurantes)


def criar_chain_sugestao_passeios() -> Runnable:
    prompt_cultural = ChatPromptTemplate.from_template(
        "Sugira 3 passeios culturais na cidade de {cidade}."
    )
    return prompt_cultural | model | StrOutputParser()


def criar_chain_previsao_tempo() -> Runnable:
    prompt_tempo = ChatPromptTemplate.from_template(
        "Forne√ßa uma previs√£o do tempo para a pr√≥xima semana em {cidade}."
    )
    return prompt_tempo | model.with_structured_output(PrevisaoTempo)


def criar_chain_resumo_final() -> Runnable:
    """Uma nova chain que cria um resumo final em Markdown, pronta para streaming."""
    prompt_resumo = ChatPromptTemplate.from_template(
        "Voc√™ √© um assistente de viagens. Com base nas informa√ß√µes a seguir, crie um roteiro de viagem "
        "atraente e bem formatado em Markdown.\n\n"
        "**Destino:** {destino.cidade}\n"
        "**Motivo:** {destino.motivo}\n\n"
        "**Previs√£o do Tempo:**\n{previsao.previsao}\n\n"
        "**Sugest√µes de Restaurantes:**\n{restaurantes.sugestoes}\n\n"
        "**Sugest√µes de Passeios:**\n{passeios}\n\n"
        "**Interesse Original do Usu√°rio:** {interesse}"
    )
    return prompt_resumo | model | StrOutputParser()


print("‚úÖ C√©lula 4: Fun√ß√µes de cria√ß√£o de chains prontas.")

# --- [C√âLULA 5] ---
# Composi√ß√£o da Chain Principal com `RunnablePassthrough.assign`
# Esta √© a forma mais moderna e leg√≠vel de compor chains que enriquecem o contexto.

roteiro_chain_completa = RunnablePassthrough.assign(
    # A primeira etapa usa o input original {"interesse": "..."} e adiciona a chave "destino"
    destino=criar_chain_sugestao_destino()
).assign(
    # As pr√≥ximas etapas usam o contexto j√° existente (que agora cont√©m "destino")
    # para popular novas chaves em paralelo.
    restaurantes=itemgetter("destino") | criar_chain_sugestao_restaurantes(),
    passeios=itemgetter("destino") | criar_chain_sugestao_passeios(),
    previsao=itemgetter("destino") | criar_chain_previsao_tempo(),
    # Mantemos o interesse original para o resumo final
    interesse=itemgetter("interesse")
) | criar_chain_resumo_final()

print("‚úÖ C√©lula 5: Chain principal composta com `assign`.")

# --- [C√âLULA 6] ---
# Execu√ß√£o Ass√≠ncrona e com Streaming
# Em um notebook, `await` pode ser usado diretamente em c√©lulas (top-level await).
# O streaming com `astream` oferece uma experi√™ncia de usu√°rio muito superior.


async def gerar_roteiro_streaming(interesse_usuario: str):
    """Executa a chain de forma ass√≠ncrona e faz o stream do resultado em Markdown."""
    display(Markdown("### ‚úàÔ∏è Gerando seu roteiro de viagem..."))

    full_response = ""
    # O `async for` itera sobre os tokens √† medida que chegam.
    async for chunk in roteiro_chain_completa.astream({"interesse": interesse_usuario}):
        full_response += chunk
        clear_output(wait=True)
        display(Markdown(full_response))

    return full_response


print("‚úÖ C√©lula 6: Fun√ß√£o de execu√ß√£o ass√≠ncrona pronta. Execute a c√©lula abaixo para come√ßar!")

# --- [C√âLULA 7] ---
# Invocando o Roteiro
# Esta seria a c√©lula que o usu√°rio executa para obter o resultado.


async def run():
    try:
        # Em um notebook, voc√™ pode simplesmente usar `await` na c√©lula:
        # await gerar_roteiro_streaming("comida de rua na √Åsia")
        await gerar_roteiro_streaming("vin√≠colas e montanhas")
    except ValueError as e:
        print(f"‚ùå Erro de configura√ß√£o: {e}")
    except Exception as e:
        print(f"üö® Ocorreu um erro inesperado durante a execu√ß√£o: {e}")


if __name__ == "__main__":
    # Para rodar como um script python
    asyncio.run(run())
