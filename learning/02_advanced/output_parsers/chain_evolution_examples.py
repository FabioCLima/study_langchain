"""Exemplos de Evolu√ß√£o de Chains no LangChain

Este arquivo demonstra a progress√£o de chains simples para complexas,
baseado no simple_chain.py como ponto de partida.

Cada exemplo mostra uma evolu√ß√£o espec√≠fica:
1. Chain b√°sica (como simple_chain.py)
2. Chain com output parser estruturado
3. Chain com m√∫ltiplos passos
4. Chain com valida√ß√£o e tratamento de erros
5. Chain com mem√≥ria e contexto
"""

import os
from typing import Any

from dotenv import find_dotenv, load_dotenv
from langchain_core.memory import ConversationBufferMemory  # type: ignore
from langchain_core.output_parsers import (  # type: ignore
    JsonOutputParser,
    StrOutputParser,
)
from langchain_core.prompts import ChatPromptTemplate  # type: ignore
from langchain_core.runnables import (  # type: ignore
    RunnablePassthrough,
    RunnableSerializable,
)
from langchain_openai import ChatOpenAI  # type: ignore
from pydantic import BaseModel, Field

# Setup b√°sico
_ = load_dotenv(find_dotenv())
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEY n√£o encontrada")

# =============================================================================
# EXEMPLO 1: CHAIN B√ÅSICA (como simple_chain.py)
# =============================================================================


def example_1_basic_chain():
    """Chain b√°sica - ponto de partida."""
    print("üîπ Exemplo 1: Chain B√°sica")
    print("=" * 50)

    # Modelo
    model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.5)  # type: ignore

    # Prompt simples
    prompt = ChatPromptTemplate.from_template(
        "Voc√™ √© um assistente √∫til. Responda a pergunta: {question}"
    )

    # Output parser b√°sico
    output_parser = StrOutputParser()

    # Chain
    chain: RunnableSerializable[
        dict[str, str], str
    ] = prompt | model | output_parser

    # Execu√ß√£o
    response = chain.invoke({"question": "O que √© intelig√™ncia artificial?"})
    print(f"Resposta: {response[:100]}...")
    print()


# =============================================================================
# EXEMPLO 2: CHAIN COM OUTPUT PARSER ESTRUTURADO
# =============================================================================


class AIResponse(BaseModel):
    """Estrutura para resposta sobre IA."""

    definition: str = Field(description="Defini√ß√£o clara e concisa")
    examples: list[str] = Field(description="Exemplos pr√°ticos")
    importance: str = Field(description="Por que √© importante")
    confidence: float = Field(description="Confian√ßa na resposta (0-1)", ge=0.0, le=1.0)


def example_2_structured_chain():
    """Chain com output parser estruturado."""
    print("üîπ Exemplo 2: Chain com Output Parser Estruturado")
    print("=" * 50)

    # Modelo
    model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)  # type: ignore

    # Prompt estruturado
    prompt = ChatPromptTemplate.from_template(
        """Voc√™ √© um especialista em intelig√™ncia artificial.
        
        Analise o conceito: {concept}
        
        Forne√ßa uma resposta estruturada com:
        - Defini√ß√£o clara
        - Exemplos pr√°ticos
        - Import√¢ncia do conceito
        - N√≠vel de confian√ßa na resposta
        
        Responda em formato JSON v√°lido."""
    )

    # Output parser estruturado
    output_parser = JsonOutputParser(pydantic_object=AIResponse)

    # Chain
    chain: RunnableSerializable[
        dict[str, str], AIResponse
    ] = prompt | model | output_parser

    # Execu√ß√£o
    response = chain.invoke({"concept": "Machine Learning"})

    print("Resposta estruturada:")
    print(f"- Defini√ß√£o: {response.definition[:80]}...")
    print(f"- Exemplos: {len(response.examples)} exemplos fornecidos")
    print(f"- Import√¢ncia: {response.importance[:80]}...")
    print(f"- Confian√ßa: {response.confidence:.2f}")
    print()


# =============================================================================
# EXEMPLO 3: CHAIN COM M√öLTIPLOS PASSOS
# =============================================================================


def example_3_multi_step_chain():
    """Chain com m√∫ltiplos passos de processamento."""
    print("üîπ Exemplo 3: Chain com M√∫ltiplos Passos")
    print("=" * 50)

    # Modelo
    model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.4)  # type: ignore

    # Passo 1: An√°lise inicial
    analysis_prompt = ChatPromptTemplate.from_template(
        """Analise o conceito: {concept}
        
        Forne√ßa:
        1. Defini√ß√£o b√°sica
        2. Categorias principais
        3. Aplica√ß√µes pr√°ticas
        
        Seja conciso e objetivo."""
    )

    # Passo 2: Gera√ß√£o de exemplos
    examples_prompt = ChatPromptTemplate.from_template(
        """Com base na an√°lise: {analysis}
        
        Gere 3 exemplos pr√°ticos e espec√≠ficos do conceito: {concept}
        
        Cada exemplo deve incluir:
        - Contexto de uso
        - Benef√≠cios
        - Limita√ß√µes"""
    )

    # Passo 3: S√≠ntese final
    synthesis_prompt = ChatPromptTemplate.from_template(
        """Com base na an√°lise e exemplos:
        
        An√°lise: {analysis}
        Exemplos: {examples}
        
        Crie uma explica√ß√£o final clara e did√°tica sobre: {concept}
        
        Inclua:
        - Resumo executivo
        - Pontos-chave
        - Recomenda√ß√µes pr√°ticas"""
    )

    # Chain multi-step
    chain: RunnableSerializable[str, str] = (
        {"concept": RunnablePassthrough()}
        | analysis_prompt
        | model
        | StrOutputParser()
        | {"analysis": RunnablePassthrough(), "concept": RunnablePassthrough()}
        | examples_prompt
        | model
        | StrOutputParser()
        | {
            "analysis": RunnablePassthrough(),
            "examples": RunnablePassthrough(),
            "concept": RunnablePassthrough(),
        }
        | synthesis_prompt
        | model
        | StrOutputParser()
    )

    # Execu√ß√£o
    response = chain.invoke("Deep Learning")

    print("Resposta multi-step:")
    print(response[:200] + "...")
    print()


# =============================================================================
# EXEMPLO 4: CHAIN COM VALIDA√á√ÉO E TRATAMENTO DE ERROS
# =============================================================================


def validate_concept(concept: str) -> bool:
    """Valida se o conceito √© apropriado para an√°lise."""
    forbidden_words = ["pornografia", "viol√™ncia", "ilegal"]
    return not any(word in concept.lower() for word in forbidden_words)


def safe_chain_execution(
    chain, input_data: dict[str, Any], max_retries: int = 3
) -> str:
    """Executa chain com tratamento de erros."""
    for attempt in range(max_retries):
        try:
            return chain.invoke(input_data)
        except Exception as e:
            if attempt == max_retries - 1:
                return f"Erro ap√≥s {max_retries} tentativas: {e!s}"
            print(f"Tentativa {attempt + 1} falhou: {e}")
    return "Erro desconhecido"


def example_4_robust_chain():
    """Chain com valida√ß√£o e tratamento de erros robusto."""
    print("üîπ Exemplo 4: Chain com Valida√ß√£o e Tratamento de Erros")
    print("=" * 50)

    # Modelo
    model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.5)  # type: ignore

    # Prompt
    prompt = ChatPromptTemplate.from_template(
        """Voc√™ √© um especialista em tecnologia.
        
        Conceito: {concept}
        
        Forne√ßa uma explica√ß√£o clara e educativa.
        Se o conceito for inadequado, explique por que n√£o pode ser analisado."""
    )

    # Output parser
    output_parser = StrOutputParser()

    # Chain
    chain: RunnableSerializable[
        dict[str, str], str
    ] = prompt | model | output_parser

    # Testes com diferentes inputs
    test_concepts = [
        "Machine Learning",
        "conte√∫do inadequado",  # Deve ser rejeitado
        "Blockchain",
    ]

    for concept in test_concepts:
        print(f"Testando conceito: {concept}")

        # Valida√ß√£o
        if not validate_concept(concept):
            print("‚ùå Conceito rejeitado por valida√ß√£o")
            continue

        # Execu√ß√£o segura
        response = safe_chain_execution(chain, {"concept": concept})
        print(f"‚úÖ Resposta: {response[:100]}...")
        print("-" * 30)
    print()


# =============================================================================
# EXEMPLO 5: CHAIN COM MEM√ìRIA E CONTEXTO
# =============================================================================


def example_5_memory_chain():
    """Chain com mem√≥ria para manter contexto da conversa."""
    print("üîπ Exemplo 5: Chain com Mem√≥ria e Contexto")
    print("=" * 50)

    # Modelo
    model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.6)  # type: ignore

    # Prompt que usa hist√≥rico
    prompt = ChatPromptTemplate.from_template(
        """Voc√™ √© um tutor de tecnologia especializado em IA.
        
        Hist√≥rico da conversa:
        {chat_history}
        
        Pergunta atual: {question}
        
        Responda de forma contextualizada, referenciando o hist√≥rico quando relevante.
        Seja did√°tico e encoraje perguntas de follow-up."""
    )

    # Mem√≥ria
    memory = ConversationBufferMemory(return_messages=True, memory_key="chat_history")

    # Output parser
    output_parser = StrOutputParser()

    # Chain com mem√≥ria
    chain: RunnableSerializable[
        dict[str, Any], str
    ] = prompt | model | output_parser

    # Simula√ß√£o de conversa
    conversation_steps = [
        "O que √© intelig√™ncia artificial?",
        "Como isso se relaciona com machine learning?",
        "Pode dar exemplos pr√°ticos de aplica√ß√µes?",
        "Quais s√£o os desafios √©ticos?",
    ]

    print("Simulando conversa com mem√≥ria:")
    for i, question in enumerate(conversation_steps, 1):
        print(f"\n--- Passo {i} ---")
        print(f"Pergunta: {question}")

        # Executa chain
        response = chain.invoke({"question": question, "chat_history": memory.buffer})

        # Atualiza mem√≥ria
        memory.save_context({"input": question}, {"output": response})

        print(f"Resposta: {response[:150]}...")
    print()


# =============================================================================
# FUN√á√ÉO PRINCIPAL
# =============================================================================


def main():
    """Executa todos os exemplos de evolu√ß√£o de chains."""
    print("üöÄ Demonstra√ß√£o de Evolu√ß√£o de Chains no LangChain")
    print("=" * 60)
    print()

    # Executa exemplos em ordem de complexidade
    example_1_basic_chain()
    example_2_structured_chain()
    example_3_multi_step_chain()
    example_4_robust_chain()
    example_5_memory_chain()

    print("‚úÖ Demonstra√ß√£o conclu√≠da!")
    print("\nüí° Dicas para evolu√ß√£o:")
    print("- Comece sempre com chains simples")
    print("- Adicione complexidade gradualmente")
    print("- Teste cada componente individualmente")
    print("- Documente suas descobertas")
    print("- Reutilize componentes bem-sucedidos")


if __name__ == "__main__":
    main()
