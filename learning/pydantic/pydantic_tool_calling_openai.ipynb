{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 5: Chamada de Ferramentas (Tool Calling) com Pydantic e OpenAI\n",
    "\n",
    "Nesta aula, você aprenderá a usar modelos Pydantic para definir ferramentas para a API de \"tool calling\" da OpenAI. Você verá como reutilizar seus modelos existentes para criar definições de ferramentas robustas e validadas, e como lidar com as chamadas de ferramentas em seu código Python. Esta lição se baseia nos seus modelos `UserInput` e `CustomerQuery` das aulas anteriores.\n",
    "\n",
    "### Conexão com LangChain e LangGraph\n",
    "Esta aula é a base para a construção de Agentes de IA. Enquanto o estado em um grafo do LangGraph é frequentemente gerenciado com `TypedDict`, as **ferramentas (tools)** que o agente utiliza precisam de um esquema claro para que o LLM saiba como usá-las. O Pydantic é a ferramenta perfeita para definir esses esquemas, garantindo que os dados passados para suas ferramentas sejam sempre válidos e bem estruturados. Dominar esta técnica é fundamental para criar agentes confiáveis.\n",
    "\n",
    "Ao final desta lição, você será capaz de:\n",
    "- Usar modelos Pydantic para definir esquemas de ferramentas para a API da OpenAI.\n",
    "- Registrar suas ferramentas na API usando um esquema validado.\n",
    "- Lidar com chamadas de ferramentas e validar os argumentos com Pydantic.\n",
    "- Integrar fluxos de trabalho orientados por LLM com suas próprias funções e fontes de dados em Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 2: Importações e Configuração\n",
    "\n",
    "**Explicação Didática:**\n",
    "Toda aplicação começa com a importação das bibliotecas necessárias. O `instructor` \"remenda\" o cliente da OpenAI, adicionando a capacidade de solicitar respostas em um formato Pydantic específico através do parâmetro `response_model`. Usamos `dotenv` para carregar nossa chave de API de um arquivo `.env` de forma segura.\n",
    "\n",
    "**Ação:** Crie um arquivo chamado `.env` no mesmo diretório deste notebook e adicione a seguinte linha:\n",
    "```\n",
    "OPENAI_API_KEY=\"sua_chave_de_api_aqui\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula de importação e configuração.\n",
    "# Se você encontrar um ModuleNotFoundError, significa que a biblioteca não está instalada.\n",
    "# Para instalar o que precisamos, execute no seu terminal:\n",
    "# pip install openai pydantic instructor python-dotenv\n",
    "\n",
    "import json\n",
    "from datetime import date, datetime\n",
    "from typing import List, Literal, Optional\n",
    "import os\n",
    "\n",
    "# A biblioteca 'instructor' é a chave para conectar Pydantic e OpenAI\n",
    "import instructor\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, EmailStr, Field, field_validator\n",
    "\n",
    "# Carrega as variáveis de ambiente (ex: OPENAI_API_KEY) do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Cria o cliente da OpenAI. O instructor vai \"remendá-lo\".\n",
    "# Isso adiciona o parâmetro 'response_model' às chamadas do cliente.\n",
    "client = instructor.patch(OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 3: Modelos Pydantic de Entrada\n",
    "\n",
    "**Explicação Didática:**\n",
    "Aqui definimos nossas estruturas de dados com Pydantic. `UserInput` representa os dados brutos que recebemos do usuário. `CustomerQuery` herda de `UserInput` e adiciona campos que serão preenchidos pelo LLM para classificar a consulta. O uso de `Field` nos permite adicionar descrições, que são cruciais para que o LLM entenda o propósito de cada campo. O `@field_validator` é um ótimo exemplo do poder do Pydantic, garantindo que um `order_id`, se fornecido, siga um formato específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o modelo para a entrada do usuário\n",
    "class UserInput(BaseModel):\n",
    "    name: str = Field(..., description=\"Nome do usuário\")\n",
    "    email: EmailStr = Field(..., description=\"Endereço de e-mail do usuário\")\n",
    "    query: str = Field(..., description=\"A pergunta/consulta do usuário\")\n",
    "    order_id: Optional[str] = Field(\n",
    "        None, description=\"ID do pedido, se disponível (formato: ABC-12345)\"\n",
    "    )\n",
    "    purchase_date: Optional[date] = Field(None, description=\"Data da compra\")\n",
    "\n",
    "    # Valida o formato do order_id (ex: ABC-12345)\n",
    "    @field_validator(\"order_id\")\n",
    "    def validate_order_id(cls, order_id):\n",
    "        import re\n",
    "\n",
    "        if order_id is None:\n",
    "            return order_id\n",
    "        pattern = r\"^[A-Z]{3}-\\d{5}$\"\n",
    "        if not re.match(pattern, order_id):\n",
    "            raise ValueError(\n",
    "                \"O order_id deve estar no formato ABC-12345 \"\n",
    "                \"(3 letras maiúsculas, traço, 5 dígitos)\"\n",
    "            )\n",
    "        return order_id\n",
    "\n",
    "# Define o modelo para a consulta classificada pelo LLM\n",
    "class CustomerQuery(UserInput):\n",
    "    priority: str = Field(..., description=\"Nível de prioridade: baixo, médio, alto\")\n",
    "    category: Literal[\"refund_request\", \"information_request\", \"other\"] = Field(\n",
    "        ..., description=\"Categoria da consulta\"\n",
    "    )\n",
    "    is_complaint: bool = Field(..., description=\"Indica se a consulta é uma reclamação\")\n",
    "    tags: List[str] = Field(..., description=\"Tags de palavras-chave relevantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 4: Função de Classificação com LLM\n",
    "\n",
    "**Explicação Didática:**\n",
    "Esta função é nosso primeiro passo de \"inteligência\". Ela recebe a entrada do usuário (já como um objeto Pydantic validado) e usa o LLM da OpenAI para enriquecê-la, transformando um `UserInput` em um `CustomerQuery`. Graças ao `instructor`, podemos passar `response_model=CustomerQuery` diretamente na chamada da API. Isso instrui o LLM a formatar sua resposta de acordo com o esquema do nosso modelo, e o `instructor` garante que o resultado seja uma instância validada do `CustomerQuery`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para chamar o LLM e criar uma instância de CustomerQuery\n",
    "def create_customer_query_openai(user_input: UserInput) -> CustomerQuery:\n",
    "    \"\"\"\n",
    "    Usa o GPT-4o para analisar a entrada do usuário e extrair/inferir os\n",
    "    campos adicionais para criar um CustomerQuery estruturado.\n",
    "    \"\"\"\n",
    "    # O 'response_model' é a mágica do instructor. Ele formata o prompt\n",
    "    # para o LLM e valida a saída, retornando um objeto Pydantic.\n",
    "    customer_query = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        response_model=CustomerQuery,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Você é um especialista em classificação de consultas de clientes. Analise a consulta do usuário e preencha os campos de prioridade, categoria, reclamação e tags.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input.model_dump_json(indent=2),\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    print(\"CustomerQuery gerado com sucesso!\")\n",
    "    return customer_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 5: Testando a Classificação\n",
    "\n",
    "**Explicação Didática:**\n",
    "Agora vamos testar a função que acabamos de criar. Fornecemos um JSON de exemplo, primeiro validamos com o nosso modelo `UserInput` e depois passamos para a função `create_customer_query_openai`. O resultado impresso mostrará o objeto Pydantic completo, com os campos `priority`, `category`, etc., preenchidos pelo LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON com a entrada de exemplo do usuário\n",
    "user_input_json = \"\"\"\n",
    "{\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe@example.com\",\n",
    "    \"query\": \"Quando posso esperar a entrega dos fones de ouvido que pedi?\",\n",
    "    \"order_id\": \"ABC-12345\",\n",
    "    \"purchase_date\": \"2025-12-01\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# 1. Valida a entrada bruta do usuário\n",
    "user_input = UserInput.model_validate_json(user_input_json)\n",
    "\n",
    "# 2. Usa o LLM para classificar e enriquecer os dados\n",
    "customer_query = create_customer_query_openai(user_input)\n",
    "\n",
    "# 3. Imprime o resultado\n",
    "print(\"\\n--- Objeto CustomerQuery Gerado ---\")\n",
    "print(customer_query.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 6: Modelos de Input para Ferramentas\n",
    "\n",
    "**Explicação Didática:**\n",
    "Aqui entramos no núcleo do \"Tool Calling\". Assim como definimos modelos para a entrada do usuário, definimos modelos Pydantic para os **argumentos** de cada ferramenta que nosso agente poderá usar. `FAQLookupArgs` define que a ferramenta de busca no FAQ precisa de uma `query` e uma lista de `tags`. `CheckOrderStatusArgs` exige um `order_id` e um `email`. Essas definições serão convertidas em JSON Schema para que o LLM saiba exatamente o que enviar ao chamar a ferramenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de argumentos para a ferramenta de busca no FAQ\n",
    "class FAQLookupArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"A pergunta original do usuário\")\n",
    "    tags: List[str] = Field(\n",
    "        ..., description=\"Tags de palavras-chave relevantes extraídas da consulta do cliente\"\n",
    "    )\n",
    "\n",
    "# Modelo de argumentos para a ferramenta de verificação de status do pedido\n",
    "class CheckOrderStatusArgs(BaseModel):\n",
    "    order_id: str = Field(..., description=\"O ID do pedido do cliente (formato: ABC-12345)\")\n",
    "    email: EmailStr = Field(..., description=\"O endereço de e-mail do cliente\")\n",
    "\n",
    "    @field_validator(\"order_id\")\n",
    "    def validate_order_id(cls, order_id):\n",
    "        import re\n",
    "        pattern = r\"^[A-Z]{3}-\\d{5}$\"\n",
    "        if not re.match(pattern, order_id):\n",
    "            raise ValueError(\"O formato do order_id deve ser ABC-12345\")\n",
    "        return order_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 7: Implementação das Ferramentas e \"Bancos de Dados\"\n",
    "\n",
    "**Explicação Didática:**\n",
    "Estas são as funções Python que nossas ferramentas irão de fato executar. `lookup_faq_answer` e `check_order_status` simulam a interação com sistemas externos (um banco de dados de FAQs e um de pedidos, que criamos como exemplos). O LLM não vê este código; ele apenas sabe o nome das funções e os argumentos que elas esperam (definidos pelos nossos modelos Pydantic na célula anterior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de dados de exemplo para o FAQ\n",
    "faq_db = [\n",
    "    {\n",
    "        \"question\": \"Como posso resetar minha senha?\",\n",
    "        \"answer\": \"Para resetar, clique em 'Esqueci a Senha' na página de login e siga as instruções.\",\n",
    "        \"keywords\": [\"senha\", \"resetar\", \"conta\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Quanto tempo leva a entrega?\",\n",
    "        \"answer\": \"A entrega padrão leva de 3 a 5 dias úteis. Você pode rastrear seu pedido no seu painel.\",\n",
    "        \"keywords\": [\"entrega\", \"envio\", \"pedido\", \"rastreamento\", \"headphones\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Base de dados de exemplo para os pedidos\n",
    "order_db = {\n",
    "    \"ABC-12345\": {\n",
    "        \"status\": \"enviado\",\n",
    "        \"estimated_delivery\": \"2025-12-05\",\n",
    "        \"email\": \"joe@example.com\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Implementação da função da ferramenta de busca no FAQ\n",
    "def lookup_faq_answer(args: FAQLookupArgs) -> str:\n",
    "    # ... (código da função original, é uma boa implementação)\n",
    "    query_words = set(word.lower() for word in args.query.split())\n",
    "    tag_set = set(tag.lower() for tag in args.tags)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    for faq in faq_db:\n",
    "        keywords = set(k.lower() for k in faq[\"keywords\"])\n",
    "        score = len(keywords & tag_set) + len(keywords & query_words)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = faq\n",
    "    if best_match and best_score > 0:\n",
    "        return best_match[\"answer\"]\n",
    "    return \"Desculpe, não encontrei uma resposta no FAQ para sua pergunta.\"\n",
    "\n",
    "\n",
    "# Implementação da função da ferramenta de status de pedido\n",
    "def check_order_status(args: CheckOrderStatusArgs) -> dict:\n",
    "    # ... (código da função original)\n",
    "    order = order_db.get(args.order_id)\n",
    "    if not order:\n",
    "        return {\"status\": \"não encontrado\"}\n",
    "    if args.email.lower() != order.get(\"email\", \"\").lower():\n",
    "        return {\"status\": \"e-mail não corresponde\"}\n",
    "    return {\"status\": order[\"status\"], \"entrega_estimada\": order[\"estimated_delivery\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 8: Definição dos Esquemas das Ferramentas para a API\n",
    "\n",
    "**Explicação Didática:**\n",
    "Esta lista `tool_definitions` é o que passaremos para a API da OpenAI. Cada item descreve uma ferramenta. O Pydantic nos ajuda imensamente aqui: `FAQLookupArgs.model_json_schema()` gera automaticamente o dicionário JSON Schema que a API precisa para o campo `parameters`. Isso é muito mais limpo e seguro do que escrevê-lo manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as ferramentas que a API da OpenAI poderá chamar\n",
    "tool_definitions = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_faq_answer\",\n",
    "            \"description\": \"Busca uma resposta no FAQ combinando tags e palavras-chave da consulta.\",\n",
    "            \"parameters\": FAQLookupArgs.model_json_schema(),\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"check_order_status\",\n",
    "            \"description\": \"Verifica o status do pedido de um cliente.\",\n",
    "            \"parameters\": CheckOrderStatusArgs.model_json_schema(),\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 9: Modelo Pydantic de Saída Final\n",
    "\n",
    "**Explicação Didática:**\n",
    "Finalmente, definimos o modelo da nossa saída final e estruturada: o `SupportTicket`. Ele herda do `CustomerQuery` (reutilizando os campos já preenchidos) e adiciona informações de ação, como a recomendação do LLM e os resultados das ferramentas que foram chamadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o modelo Pydantic para a saída final\n",
    "class OrderDetails(BaseModel):\n",
    "    status: str\n",
    "    entrega_estimada: Optional[str] = None\n",
    "\n",
    "class SupportTicket(CustomerQuery):\n",
    "    recommended_next_action: Literal[\n",
    "        \"escalate_to_agent\", \"send_faq_response\", \"send_order_status\", \"no_action_needed\"\n",
    "    ] = Field(..., description=\"A próxima ação recomendada pelo LLM para o suporte\")\n",
    "    order_details: Optional[OrderDetails] = Field(\n",
    "        None, description=\"Detalhes do pedido se a ação for 'send_order_status'\"\n",
    "    )\n",
    "    faq_response: Optional[str] = Field(\n",
    "        None, description=\"Resposta do FAQ se a ação for 'send_faq_response'\"\n",
    "    )\n",
    "    creation_date: datetime = Field(\n",
    "        default_factory=datetime.now, description=\"Data e hora de criação do ticket\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 10: Fluxo de Orquestração com Múltiplas Chamadas\n",
    "\n",
    "**Explicação Didática:**\n",
    "Esta é a função principal que orquestra todo o processo.\n",
    "1.  **Primeira Chamada (Decisão):** Envia a consulta do usuário e a lista de ferramentas disponíveis para o OpenAI. O LLM decide se pode responder diretamente ou se precisa chamar uma ferramenta.\n",
    "2.  **Execução da Ferramenta:** Se o LLM solicitar uma chamada de ferramenta, nosso código Python executa a função correspondente (`lookup_faq_answer` ou `check_order_status`).\n",
    "3.  **Segunda Chamada (Síntese):** Enviamos uma nova mensagem para o LLM, desta vez incluindo o resultado da ferramenta. O LLM então usa essa nova informação para gerar a resposta final e preencher nosso `SupportTicket`.\n",
    "4.  **Geração Estruturada:** Usamos o `instructor` novamente na chamada final para garantir que a saída seja um objeto `SupportTicket` validado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_support_workflow(customer_query: CustomerQuery) -> SupportTicket:\n",
    "    \"\"\"\n",
    "    Orquestra o fluxo completo: decide a ação, chama ferramentas se necessário,\n",
    "    e gera o ticket de suporte final.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Passo 1: Decidindo a próxima ação ---\")\n",
    "    # O prompt do sistema instrui o LLM sobre seu papel e as ferramentas disponíveis\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Você é um agente de suporte. Use as ferramentas disponíveis para obter informações adicionais (como status de pedido ou respostas de FAQ) antes de decidir a próxima ação.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Consulta do cliente: {customer_query.model_dump_json()}\"},\n",
    "    ]\n",
    "\n",
    "    # Primeira chamada: O LLM decide se precisa de uma ferramenta\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tool_definitions,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "\n",
    "    # Adiciona a resposta da IA (que pode incluir pedidos de ferramenta) ao histórico\n",
    "    messages.append(response_message)\n",
    "\n",
    "    if tool_calls:\n",
    "        print(f\"\\n--- Passo 2: LLM solicitou {len(tool_calls)} chamada(s) de ferramenta ---\")\n",
    "        available_functions = {\n",
    "            \"lookup_faq_answer\": lookup_faq_answer,\n",
    "            \"check_order_status\": check_order_status,\n",
    "        }\n",
    "        # Executa cada ferramenta solicitada\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            # Valida os argumentos com Pydantic antes de chamar a função\n",
    "            if function_name == \"lookup_faq_answer\":\n",
    "                function_args_model = FAQLookupArgs.model_validate_json(tool_call.function.arguments)\n",
    "            else:\n",
    "                function_args_model = CheckOrderStatusArgs.model_validate_json(tool_call.function.arguments)\n",
    "\n",
    "            print(f\"Executando: {function_name}({function_args_model.model_dump()})\")\n",
    "            function_response = function_to_call(function_args_model)\n",
    "\n",
    "            # Adiciona o resultado da ferramenta ao histórico de mensagens\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(function_response),\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        print(\"\\n--- Passo 3: Gerando o ticket final com o resultado da ferramenta ---\")\n",
    "        # Segunda chamada: O LLM usa o resultado da ferramenta para gerar a saída final\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            response_model=SupportTicket, # Usando instructor para a saída final\n",
    "        )\n",
    "        return final_response\n",
    "    else:\n",
    "        print(\"\\n--- Passo 2 e 3: Nenhuma ferramenta foi chamada. Gerando ticket diretamente. ---\")\n",
    "        # Se nenhuma ferramenta foi necessária, pedimos o ticket final mesmo assim\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            response_model=SupportTicket,\n",
    "        )\n",
    "        return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 11: Executando o Fluxo Completo\n",
    "\n",
    "**Explicação Didática:**\n",
    "Aqui, executamos o fluxo completo com a consulta do nosso cliente. O resultado final será um `SupportTicket` completo e bem estruturado, que poderia ser facilmente salvo em um banco de dados ou enviado para outro sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa o fluxo completo\n",
    "support_ticket = run_support_workflow(customer_query)\n",
    "\n",
    "# Imprime o ticket de suporte final e validado\n",
    "print(\"\\n--- Ticket de Suporte Final Gerado ---\")\n",
    "print(support_ticket.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 12: Conclusão\n",
    "\n",
    "**Explicação Didática:**\n",
    "Para finalizar, um resumo do que aprendemos. Esta célula reforça a importância do Pydantic na criação de sistemas de IA confiáveis, conectando a validação de dados de entrada, a definição de ferramentas e a geração de saídas estruturadas, que são os blocos de construção para os agentes que você está estudando em LangChain e LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Conclusão\n",
    "\n",
    "Nesta lição, você aprendeu a usar modelos Pydantic para definir ferramentas para a API de \"tool calling\" da OpenAI e a construir um fluxo de trabalho de suporte ao cliente do início ao fim. Você viu como reutilizar modelos para criar definições de ferramentas robustas, lidar com as chamadas de API, executar a lógica correspondente em Python e, finalmente, gerar uma saída estruturada e validada.\n",
    "\n",
    "Esta abordagem demonstra o poder do Pydantic na criação de pipelines de IA confiáveis. A validação em cada etapa – da entrada do usuário, passando pelos argumentos das ferramentas, até a saída final – é o que permite que Agentes de IA complexos, como os construídos com LangChain e LangGraph, operem de forma segura e previsível."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}