"""Script LangChain: InformaÃ§Ãµes de PaÃ­ses com LangSmith Tracing
===========================================================

Este script demonstra como criar uma pipeline no LangChain com monitoramento
via LangSmith para melhor debugging e entendimento das chains.

Funcionalidades demonstradas:
- Pydantic Settings para configuraÃ§Ã£o
- LangSmith para tracing e debugging
- Structured Output para dados tipados
- Chain composition com RunnablePassthrough
- Tratamento de erros e logging
"""

import os

from dotenv import find_dotenv, load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field, SecretStr, ValidationError
from pydantic_settings import BaseSettings

# LangSmith imports para tracing
# LangSmith imports (com tratamento de erro se nÃ£o estiver instalado)
try:
    import langchain
    from langchain_core.tracers.langchain import LangChainTracer
    from langsmith import Client
    LANGSMITH_AVAILABLE = True
except ImportError:
    # Define uma classe dummy se LangSmith nÃ£o estiver disponÃ­vel
    class Client:
        def __init__(self, *args, **kwargs):
            pass
    LANGSMITH_AVAILABLE = False


# ============================================================
# 1. CONFIGURAÃ‡Ã•ES COM LANGSMITH
# ============================================================
class AppSettings(BaseSettings):
    """ConfiguraÃ§Ãµes da aplicaÃ§Ã£o com suporte ao LangSmith.
    
    O LangSmith oferece:
    - Tracing detalhado de chains
    - Debugging visual
    - MÃ©tricas de performance
    - ComparaÃ§Ã£o de execuÃ§Ãµes
    """

    # Chaves de API obrigatÃ³rias
    openai_api_key: SecretStr = Field(
        ...,
        description="Chave da API OpenAI"
    )

    # LangSmith - opcional mas recomendado
    langsmith_api_key: SecretStr | None = Field(
        default=None,
        description="Chave da API LangSmith (opcional)"
    )

    # ConfiguraÃ§Ãµes do LangSmith
    langsmith_tracing: bool = Field(
        default=False,
        description="Habilitar tracing do LangSmith"
    )

    langsmith_project: str = Field(
        default="country-info-pipeline",
        description="Nome do projeto no LangSmith"
    )

    langsmith_endpoint: str = Field(
        default="https://api.smith.langchain.com",
        description="Endpoint do LangSmith"
    )

    # ConfiguraÃ§Ãµes do modelo
    model_name: str = Field(
        default="gpt-4o-mini",
        description="Nome do modelo OpenAI"
    )

    temperature_structured: float = Field(
        default=0.1,
        description="Temperature para outputs estruturados"
    )

    temperature_creative: float = Field(
        default=0.7,
        description="Temperature para conteÃºdo criativo"
    )

    class Config:
        env_file = find_dotenv()
        env_file_encoding = "utf-8"


def setup_langsmith(settings: AppSettings) -> Client | None:
    """Configura o LangSmith para tracing.
    
    Args:
        settings: ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
        
    Returns:
        Client do LangSmith se configurado, None caso contrÃ¡rio

    """
    if not LANGSMITH_AVAILABLE:
        print("âš ï¸  LangSmith nÃ£o estÃ¡ instalado. Instale com: pip install langsmith")
        return None

    if not settings.langsmith_tracing or not settings.langsmith_api_key:
        print("â„¹ï¸  LangSmith tracing desabilitado")
        return None

    try:
        # Configura variÃ¡veis de ambiente para LangSmith
        os.environ["LANGCHAIN_TRACING_V2"] = "true"
        os.environ["LANGCHAIN_API_KEY"] = settings.langsmith_api_key.get_secret_value()
        os.environ["LANGCHAIN_PROJECT"] = settings.langsmith_project
        os.environ["LANGCHAIN_ENDPOINT"] = settings.langsmith_endpoint

        # Habilita tracing global (sÃ³ se langchain estiver disponÃ­vel)
        if "langchain" in globals():
            langchain.debug = True

        # Cria client do LangSmith
        client = Client(
            api_key=settings.langsmith_api_key.get_secret_value(),
            api_url=settings.langsmith_endpoint
        )

        print("âœ… LangSmith configurado!")
        print(f"ğŸ“Š Projeto: {settings.langsmith_project}")
        print("ğŸ”— Dashboard: https://smith.langchain.com/")

        return client

    except Exception as e:
        print(f"âš ï¸  Erro ao configurar LangSmith: {e}")
        print("â„¹ï¸  Continuando sem tracing...")
        return None


def load_settings() -> AppSettings:
    """Carrega e valida as configuraÃ§Ãµes.
    
    Returns:
        AppSettings: ConfiguraÃ§Ãµes validadas
        
    Raises:
        ValidationError: Se alguma configuraÃ§Ã£o obrigatÃ³ria estiver faltando

    """
    try:
        load_dotenv(find_dotenv())
        return AppSettings()
    except ValidationError as e:
        print(f"âŒ Erro nas configuraÃ§Ãµes: {e}")
        print("ğŸ’¡ Certifique-se de ter um arquivo .env com pelo menos OPENAI_API_KEY")
        raise


# ============================================================
# 2. MODELOS DE DADOS
# ============================================================
class CountryInfo(BaseModel):
    """Modelo para informaÃ§Ãµes estruturadas de um paÃ­s."""

    nome: str = Field(description="Nome oficial do paÃ­s")
    capital: str = Field(description="Capital do paÃ­s")

    def __str__(self) -> str:
        return f"{self.nome} - Capital: {self.capital}"


# ============================================================
# 3. CONFIGURAÃ‡ÃƒO DOS MODELOS
# ============================================================
def create_structured_model(settings: AppSettings) -> ChatOpenAI:
    """Cria modelo para outputs estruturados.
    
    Com LangSmith, vocÃª poderÃ¡ ver:
    - Tempo de resposta do modelo
    - Tokens utilizados
    - Custo da operaÃ§Ã£o
    - Prompt exato enviado
    """
    return ChatOpenAI(
        api_key=settings.openai_api_key.get_secret_value(),
        model=settings.model_name,
        temperature=settings.temperature_structured,
        # Adiciona metadados para melhor tracing
        model_kwargs={"metadata": {"component": "structured_output"}}
    ).with_structured_output(CountryInfo)


def create_creative_model(settings: AppSettings) -> ChatOpenAI:
    """Cria modelo para conteÃºdo criativo.
    
    Com LangSmith, vocÃª poderÃ¡ comparar:
    - Performance entre diferentes temperatures
    - Qualidade das respostas criativas
    - Variabilidade dos outputs
    """
    return ChatOpenAI(
        api_key=settings.openai_api_key.get_secret_value(),
        model=settings.model_name,
        temperature=settings.temperature_creative,
        # Metadados para tracking
        model_kwargs={"metadata": {"component": "creative_content"}}
    )


# ============================================================
# 4. CHAINS COM TRACING MELHORADO
# ============================================================
def create_country_chain(model: ChatOpenAI):
    """Chain para obter informaÃ§Ãµes do paÃ­s.
    
    O LangSmith mostrarÃ¡:
    - Input: nome do paÃ­s
    - Prompt completo enviado ao modelo
    - Resposta estruturada do modelo
    - Tempo de execuÃ§Ã£o
    """
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "VocÃª Ã© um especialista em geografia mundial. "
         "ForneÃ§a informaÃ§Ãµes precisas sobre paÃ­ses. "
         "Responda SEMPRE com o nome oficial do paÃ­s e sua capital."),
        ("user", "Qual Ã© a capital de {pais}?")
    ])

    # Adiciona nome para melhor identificaÃ§Ã£o no tracing
    chain = prompt | model
    chain.name = "CountryInfoChain"

    return chain


def create_curiosity_chain(model: ChatOpenAI):
    """Chain para curiosidades sobre cidades.
    
    No LangSmith vocÃª verÃ¡:
    - Como a capital foi extraÃ­da da chain anterior
    - Prompt especÃ­fico para curiosidades
    - Criatividade da resposta (temperature 0.7)
    """
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "VocÃª Ã© um guia turÃ­stico especializado mundial. "
         "Conte curiosidades interessantes, verÃ­dicas e pouco conhecidas sobre cidades. "
         "Seja especÃ­fico e envolvente na sua resposta."),
        ("user", "Conte uma curiosidade fascinante sobre {cidade}")
    ])

    chain = prompt | model
    chain.name = "CuriosityChain"

    return chain


# ============================================================
# 5. PIPELINE COM TRACING DETALHADO
# ============================================================
def create_main_pipeline(settings: AppSettings, langsmith_client: Client | None = None):
    """Cria a pipeline principal com tracing detalhado.
    
    Com LangSmith habilitado, vocÃª verÃ¡:
    1. Input inicial: {'pais': 'Nome do PaÃ­s'}
    2. ExecuÃ§Ã£o da CountryInfoChain
    3. ExtraÃ§Ã£o da capital
    4. ExecuÃ§Ã£o da CuriosityChain
    5. FormataÃ§Ã£o final
    6. Tempo total e custos
    """
    # Criar modelos
    structured_model = create_structured_model(settings)
    creative_model = create_creative_model(settings)

    # Criar chains individuais
    country_chain = create_country_chain(structured_model)
    curiosity_chain = create_curiosity_chain(creative_model)

    # FunÃ§Ã£o para extrair capital (com melhor tracing)
    def extract_capital(data: dict) -> dict:
        """Extrai a capital do CountryInfo.
        
        No LangSmith vocÃª verÃ¡ exatamente:
        - Input: objeto CountryInfo completo
        - Output: {'cidade': 'Nome da Capital'}
        """
        capital = data["country_info"].capital
        print(f"ğŸ”„ Extraindo capital: {capital}")
        return {"cidade": capital}

    # Sub-chain com nome para tracking
    capital_extractor = RunnableLambda(extract_capital)
    capital_extractor.name = "CapitalExtractor"

    capital_to_curiosity = capital_extractor | curiosity_chain
    capital_to_curiosity.name = "CapitalToCuriosity"

    # FunÃ§Ã£o de formataÃ§Ã£o com logging
    def format_result(data: dict) -> str:
        """Formata resultado final com logging para debug.
        """
        country = data["country_info"]
        curiosity = data["curiosity"]

        print(f"ğŸ“Š Formatando resultado para: {country.nome}")

        result = f"""
ğŸŒ INFORMAÃ‡Ã•ES DO PAÃS
{'=' * 50}
ğŸ“ PaÃ­s: {country.nome}
ğŸ›ï¸  Capital: {country.capital}

âœ¨ CURIOSIDADE SOBRE {country.capital.upper()}
{'=' * 50}
{curiosity.content}

ğŸ” Para ver o tracing detalhado desta execuÃ§Ã£o,
   acesse: https://smith.langchain.com/
        """.strip()

        return result

    formatter = RunnableLambda(format_result)
    formatter.name = "ResultFormatter"

    # Pipeline completa com nomes para melhor tracing
    pipeline = (
        RunnablePassthrough.assign(country_info=country_chain)
        | RunnablePassthrough.assign(curiosity=capital_to_curiosity)
        | formatter
    )

    # Nome da pipeline principal
    pipeline.name = "CountryInfoPipeline"

    return pipeline


# ============================================================
# 6. FUNÃ‡ÃƒO PRINCIPAL COM TRACING
# ============================================================
def consultar_pais(
    nome_pais: str,
    settings: AppSettings | None = None,
    enable_tracing: bool = True
) -> str:
    """Consulta informaÃ§Ãµes de um paÃ­s com tracing opcional.
    
    Args:
        nome_pais: Nome do paÃ­s
        settings: ConfiguraÃ§Ãµes (carrega automaticamente se None)
        enable_tracing: Se deve tentar usar LangSmith
        
    Returns:
        str: InformaÃ§Ãµes formatadas

    """
    try:
        # Carrega configuraÃ§Ãµes
        if settings is None:
            settings = load_settings()

        # Configura LangSmith se habilitado
        langsmith_client = None
        if enable_tracing and settings.langsmith_tracing:
            langsmith_client = setup_langsmith(settings)

        # Cria e executa pipeline
        pipeline = create_main_pipeline(settings, langsmith_client)

        # ExecuÃ§Ã£o com contexto de tracing
        print(f"ğŸš€ Executando pipeline para: {nome_pais}")
        if langsmith_client:
            print("ğŸ“Š Tracing habilitado - verifique o LangSmith dashboard")

        resultado = pipeline.invoke({"pais": nome_pais})

        return resultado

    except Exception as e:
        error_msg = f"âŒ Erro ao consultar '{nome_pais}': {e!s}"
        print(error_msg)
        return error_msg


# ============================================================
# 7. FUNÃ‡Ã•ES DE ANÃLISE DO LANGSMITH
# ============================================================
def analisar_execucoes(settings: AppSettings, project_name: str | None = None):
    """Analisa execuÃ§Ãµes no LangSmith (requer configuraÃ§Ã£o).
    
    Esta funÃ§Ã£o demonstra como vocÃª pode usar o LangSmith client
    para analisar runs anteriores e obter insights.
    """
    if not LANGSMITH_AVAILABLE:
        print("âš ï¸  LangSmith nÃ£o estÃ¡ disponÃ­vel. Instale com: pip install langsmith")
        return

    if not settings.langsmith_api_key:
        print("âš ï¸  LangSmith API key nÃ£o configurada")
        return

    try:
        client = Client(
            api_key=settings.langsmith_api_key.get_secret_value(),
            api_url=settings.langsmith_endpoint
        )

        project = project_name or settings.langsmith_project

        # Busca runs recentes
        runs = list(client.list_runs(project_name=project, limit=5))

        print(f"\nğŸ“Š ANÃLISE - Ãšltimas 5 execuÃ§Ãµes do projeto '{project}':")
        print("=" * 60)

        for i, run in enumerate(runs, 1):
            status = "âœ…" if not run.error else "âŒ"
            duration = f"{run.total_time:.2f}s" if run.total_time else "N/A"

            print(f"{i}. {status} {run.name}")
            print(f"   â±ï¸  DuraÃ§Ã£o: {duration}")
            print(f"   ğŸ†” ID: {run.id}")
            if run.error:
                print(f"   âŒ Erro: {run.error}")
            print()

    except Exception as e:
        print(f"âŒ Erro ao analisar execuÃ§Ãµes: {e}")


# ============================================================
# 8. EXEMPLO DE USO COM LANGSMITH
# ============================================================
def main():
    """FunÃ§Ã£o principal demonstrando uso com LangSmith."""
    print("ğŸš€ Iniciando aplicaÃ§Ã£o LangChain com LangSmith")
    print("=" * 60)

    try:
        # Carrega configuraÃ§Ãµes
        settings = load_settings()
        print("âœ… ConfiguraÃ§Ãµes carregadas!")

        # Mostra status das configuraÃ§Ãµes
        api_key = settings.openai_api_key.get_secret_value()
        print(f"ğŸ”‘ OpenAI API: {api_key[:8]}...{api_key[-4:]}")

        if settings.langsmith_api_key:
            ls_key = settings.langsmith_api_key.get_secret_value()
            print(f"ğŸ“Š LangSmith API: {ls_key[:8]}...{ls_key[-4:]}")
            print(f"ğŸ¯ Projeto: {settings.langsmith_project}")
        else:
            print("â„¹ï¸  LangSmith nÃ£o configurado")

        print(f"ğŸ¤– Modelo: {settings.model_name}")
        print()

        # Exemplo de uso
        paises = ["Brasil", "JapÃ£o"]

        for pais in paises:
            print(f"ğŸ” Consultando: {pais}")
            print("-" * 40)

            resultado = consultar_pais(pais, settings)
            print(resultado)
            print("\n" + "=" * 60 + "\n")

        # AnÃ¡lise das execuÃ§Ãµes (se LangSmith configurado)
        if settings.langsmith_api_key:
            analisar_execucoes(settings)

    except Exception as e:
        print(f"âŒ Erro na execuÃ§Ã£o: {e}")
        return 1

    return 0


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
