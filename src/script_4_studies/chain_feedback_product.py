# Jupyter Notebook: Cadeia de An√°lise de Feedback de Produto com LangChain

# ## 1. Configura√ß√£o Inicial

import os

from dotenv import find_dotenv, load_dotenv
from langchain_openai import ChatOpenAI

_ = load_dotenv(find_dotenv())
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEY n√£o encontrada no .env")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.0)

# ## 2. Logging e Parser

import time

from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import (
    RunnableLambda,
    RunnableParallel,
    RunnablePassthrough,
)

debug_logs = []


def log_event(data):
    debug_logs.append({"timestamp": time.time(), "message": data})


log_chain = RunnableLambda(log_event) | RunnablePassthrough()
parser = StrOutputParser()

# ## 3. Prompts e Cadeias Individuais

from langchain_core.prompts import PromptTemplate

# Etapa 1: Extrair o problema principal do feedback
feedback_prompt = PromptTemplate.from_template(
    """
    Voc√™ √© um analista de produto. A partir do seguinte feedback do usu√°rio,
    extraia o principal problema relatado:

    Feedback: {feedback}

    Resuma em uma frase clara o problema principal.
    """
)
feedback_chain = feedback_prompt | llm | RunnableParallel(output=parser, log=log_chain)

# Etapa 2: Gerar uma sugest√£o de melhoria
suggestion_prompt = PromptTemplate.from_template(
    """
    Considere o seguinte problema de produto:
    Problema: {problem}

    Sugira uma melhoria concreta e objetiva para a equipe de produto.
    """
)
suggestion_chain = suggestion_prompt | llm | RunnableParallel(output=parser, log=log_chain)

# ## 4. Estrutura√ß√£o com Pydantic

from pydantic import BaseModel, Field


class FeedbackReport(BaseModel):
    problem_summary: str = Field(description="Resumo do problema identificado")
    severity: str = Field(description="Gravidade estimada do problema (baixa, m√©dia, alta)")
    category: str = Field(description="Categoria geral do problema")
    suggested_fix: str = Field(description="Solu√ß√£o sugerida para o problema")


report_prompt = PromptTemplate.from_template(
    """
    Com base no problema e na sugest√£o a seguir, estruture um relat√≥rio com os seguintes campos:
    - Resumo do problema
    - Categoria (ex: usabilidade, desempenho, bug, funcionalidade, etc)
    - Gravidade (baixa, m√©dia ou alta)
    - Sugest√£o de solu√ß√£o

    Problema: {problem}
    Sugest√£o: {suggestion}

    Retorne o resultado em formato JSON estruturado.
    """
)

report_chain = report_prompt | llm.with_structured_output(schema=FeedbackReport)

# ## 5. Composi√ß√£o da Cadeia Final

from operator import itemgetter

full_chain = (
    feedback_chain
    | RunnableParallel(problem=itemgetter("output"))
    | (
        RunnableParallel(
            suggestion=suggestion_chain,
            problem=itemgetter("problem")
        )
    )
    | RunnableParallel(
        problem=itemgetter("problem"),
        suggestion=itemgetter("suggestion")
    )
    | report_chain
)

# ## 6. Execu√ß√£o da Cadeia com um Exemplo

if __name__ == "__main__":
    example_feedback = {
        "feedback": "O aplicativo trava sempre que tento adicionar um novo cart√£o de cr√©dito. Isso acontece toda vez que clico no bot√£o de salvar."
    }

    report = full_chain.invoke(example_feedback)

    print("\nüìã Relat√≥rio Gerado:")
    print("Resumo:", report.problem_summary)
    print("Categoria:", report.category)
    print("Gravidade:", report.severity)
    print("Sugest√£o:", report.suggested_fix)

    print("\nüìö Total de Logs Registrados:", len(debug_logs))
